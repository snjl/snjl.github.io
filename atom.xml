<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>snjl</title>
  
  <subtitle>我大概率会编程。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://snjl.github.io/"/>
  <updated>2019-02-03T16:02:27.869Z</updated>
  <id>https://snjl.github.io/</id>
  
  <author>
    <name>snjl</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>爬取今日头条街拍图片</title>
    <link href="https://snjl.github.io/2019/02/03/%E7%88%AC%E5%8F%96%E4%BB%8A%E6%97%A5%E5%A4%B4%E6%9D%A1%E8%A1%97%E6%8B%8D%E5%9B%BE%E7%89%87/"/>
    <id>https://snjl.github.io/2019/02/03/爬取今日头条街拍图片/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:02:27.869Z</updated>
    
    <content type="html"><![CDATA[<p>项目地址：<a href="https://github.com/snjl/python.spider.jiepai.git" target="_blank" rel="noopener">https://github.com/snjl/python.spider.jiepai.git</a></p><h1 id="爬取网址"><a href="#爬取网址" class="headerlink" title="爬取网址"></a>爬取网址</h1><p><a href="https://www.toutiao.com/search/?keyword=%E8%A1%97%E6%8B%8D" target="_blank" rel="noopener">https://www.toutiao.com/search/?keyword=%E8%A1%97%E6%8B%8D</a></p><h1 id="前期研究"><a href="#前期研究" class="headerlink" title="前期研究"></a>前期研究</h1><p>访问网址后，会发现列表页有多种形式，第一种是视频，第二种是广告，第三种是所有图片在一个网页里面，第四种是图片需要跳转，我们做的是第四种。</p><p>通过f12开发者工具可以看到比较详细的信息。<br><strong>点preserve log，可以刷新时保留记录，点XHR，可以看到传输过来的ajax数据。</strong></p><h2 id="列表页分析"><a href="#列表页分析" class="headerlink" title="列表页分析"></a>列表页分析</h2><p>列表是通过ajax传输过来的，参数有多个，在python爬取的时候需要传输：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;</span><br><span class="line">    &apos;aid&apos;: 24,</span><br><span class="line">    &apos;offset&apos;: offset,</span><br><span class="line">    &apos;format&apos;: &apos;json&apos;,</span><br><span class="line">    &apos;keyword&apos;: keyword,</span><br><span class="line">    &apos;autoload&apos;: &apos;true&apos;,</span><br><span class="line">    &apos;count&apos;: 20,</span><br><span class="line">    &apos;cur_tab&apos;: 3,</span><br><span class="line">    &apos;from&apos;: &apos;gallery&apos;,</span><br><span class="line">    &apos;pd&apos;: &apos;synthesis&apos;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>其中keyword是可以改变的，offset是偏移值，一般是为20的倍数，因为每次json传输20个数据。</p><p>列表页需要获取的是每个详情页的title和url。</p><h2 id="详情页分析"><a href="#详情页分析" class="headerlink" title="详情页分析"></a>详情页分析</h2><p>分析详情页，可以发现每次跳转网页实际上不是ajax交互，而是在初始的网页中有数据，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    gallery: JSON.parse(&quot;&#123;\&quot;count\&quot;:9,\&quot;sub_images\&quot;:[&#123;\&quot;url\&quot;:\&quot;http:\\/\\/p1.pstatp.com\\/origin\\/pgc-image\\/e4de890cc2084bc5b3557ee5b6ea0ed9\&quot;,\&quot;width\&quot;:800,\&quot;url_list\&quot;:[&#123;\&quot;url\&quot;:\&quot;http:\\/\\/p1.pstatp.com\\/origin\\/pgc-image\\/e4de890cc2084bc5b3557ee5b6ea0ed9\&quot;&#125;,</span><br><span class="line"></span><br><span class="line">···</span><br></pre></td></tr></table></figure></p><p>所以实际上已经把图的地址写在doc里，拿到网页的url，然后通过正则获取就可以得到地址。</p><h1 id="代码功能"><a href="#代码功能" class="headerlink" title="代码功能"></a>代码功能</h1><h2 id="三部分"><a href="#三部分" class="headerlink" title="三部分"></a>三部分</h2><h3 id="列表页"><a href="#列表页" class="headerlink" title="列表页"></a>列表页</h3><p>列表页需要两个函数，第一个是获取列表页的的response.text（需要进行错误处理），第二个是对列表页进行解析，获取到需要抓取的详情页的一些信息。</p><h3 id="详情页"><a href="#详情页" class="headerlink" title="详情页"></a>详情页</h3><p>详情页里，需要通过正则获取到所有需要下载的链接，所以也是两个函数，一个获取详情页的response.text，一个获取详情页中的下载信息。</p><h3 id="数据库、图片下载等"><a href="#数据库、图片下载等" class="headerlink" title="数据库、图片下载等"></a>数据库、图片下载等</h3><p>数据库使用mongodb，这里的代码可以插入在详情页的下载信息或者main函数中每次处理完一个详情页信息后进行存储；</p><p>图片下载同样处理，也可以放在获取到详情页的下载链接后的for循环遍历。</p><h2 id="具体代码"><a href="#具体代码" class="headerlink" title="具体代码"></a>具体代码</h2><h3 id="列表页-1"><a href="#列表页-1" class="headerlink" title="列表页"></a>列表页</h3><p>获取列表页response.text<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">def get_page_index(offset, keyword):</span><br><span class="line">    data = &#123;</span><br><span class="line">        &apos;aid&apos;: 24,</span><br><span class="line">        &apos;offset&apos;: offset,</span><br><span class="line">        &apos;format&apos;: &apos;json&apos;,</span><br><span class="line">        &apos;keyword&apos;: keyword,</span><br><span class="line">        &apos;autoload&apos;: &apos;true&apos;,</span><br><span class="line">        &apos;count&apos;: 20,</span><br><span class="line">        &apos;cur_tab&apos;: 3,</span><br><span class="line">        &apos;from&apos;: &apos;gallery&apos;,</span><br><span class="line">        &apos;pd&apos;: &apos;synthesis&apos;,</span><br><span class="line">    &#125;</span><br><span class="line">    url = &apos;https://www.toutiao.com/api/search/content/?&apos; + urlencode(data)</span><br><span class="line">    print(url)</span><br><span class="line">    try:</span><br><span class="line">        response = requests.get(url=url, headers=headers)</span><br><span class="line">        if response.status_code == 200:</span><br><span class="line">            response.encoding = &apos;utf8&apos;  # 原编码不是utf8，会有一定乱码</span><br><span class="line">            return response.text</span><br><span class="line">        return None</span><br><span class="line">    except RequestException as e:</span><br><span class="line">        print(e)</span><br><span class="line">        print(&quot;请求json出错&quot;)</span><br><span class="line">        return None</span><br></pre></td></tr></table></figure></p><p>传入keyword，offset获取列表页text。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def parse_page_index(html):</span><br><span class="line">    try:</span><br><span class="line">        data = json.loads(html)</span><br><span class="line">        # 判断data不为空，且&apos;data&apos;在keys中，并且data[&apos;data&apos;]不为空</span><br><span class="line">        if data and &apos;data&apos; in data.keys() and data[&apos;data&apos;]:</span><br><span class="line">            items = data[&apos;data&apos;]</span><br><span class="line">            for item in items:</span><br><span class="line">                # 判断abstract为空，且app_info存在，且item[&apos;app_info&apos;][&apos;db_name&apos;]为SITE</span><br><span class="line">                if item and &apos;abstract&apos; in item.keys() and \</span><br><span class="line">                        item[&apos;abstract&apos;] == &apos;&apos; and &apos;app_info&apos; in item.keys() \</span><br><span class="line">                        and item[&apos;app_info&apos;][&apos;db_name&apos;] == &apos;SITE&apos;:</span><br><span class="line">                    yield &#123;</span><br><span class="line">                        &apos;title&apos;: item[&apos;title&apos;],</span><br><span class="line">                        &apos;url&apos;: item[&apos;article_url&apos;]</span><br><span class="line">                    &#125;</span><br><span class="line">    except JSONDecodeError as e:</span><br><span class="line">        print(e)</span><br></pre></td></tr></table></figure></p><p>由于拿到的是ajjax的json数据，所以可以通过json.loads()方法解析到数据，然后判断data是否为空，data里面是否有‘data’字段，如果有的话判断里面的每一个item是否有’abstract’字段和’app_info’字段，如果有，里面字段’db_name’的值为SITE（其实还是有误差）的才是第四类，通过这种方式获取的列表页信息才是比较干净的数据。最后返回title和url数据。</p><h3 id="详情页-1"><a href="#详情页-1" class="headerlink" title="详情页"></a>详情页</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def get_page_detail(url):</span><br><span class="line">    try:</span><br><span class="line">        response = requests.get(url=url, headers=headers)</span><br><span class="line">        if response.status_code == 200:</span><br><span class="line">            return response.text</span><br><span class="line">        return None</span><br><span class="line">    except RequestException as e:</span><br><span class="line">        print(e)</span><br><span class="line">        print(&quot;请求详情页出错&quot;)</span><br><span class="line">        return None</span><br></pre></td></tr></table></figure><p>获取详情页response.text代码。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def parse_page_detail(html):</span><br><span class="line">    images_pattern = re.compile(&apos;gallery: JSON.parse\(&quot;(.*?)&quot;\)&apos;)</span><br><span class="line">    result = re.search(images_pattern, html)</span><br><span class="line">    if result:</span><br><span class="line">        result_data = re.sub(r&apos;\\&apos;, &apos;&apos;, result.group(1))</span><br><span class="line">        data = json.loads(result_data)</span><br><span class="line">        images = [sub_image[&apos;url&apos;] for sub_image in data[&apos;sub_images&apos;]]</span><br><span class="line">        for image in images:</span><br><span class="line">            download_image(image)</span><br><span class="line">        return images</span><br></pre></td></tr></table></figure></p><p>通过正则，获取内容后，由于反斜杠‘\’的存在影响了我们的进一步操作，因此，有必要把反斜杠去掉，需要注意的是，这里显示的每一个反斜杠，实际上源字符串中都有两个反斜杠，还有一个反斜杠是用来转义的，故print是并不显示。</p><p>因此，我们要实际上要去掉的是两个连续的反斜杠，使用re.sbu(r’\’,’’,results)进行替换</p><p>处理后，获得的就是一个images的url的list列表（此处还调用了一个下载图片的函数，后续会介绍），然后返回。</p><h3 id="数据库和图片下载代码等"><a href="#数据库和图片下载代码等" class="headerlink" title="数据库和图片下载代码等"></a>数据库和图片下载代码等</h3><p>数据库可以使用配置类，所以另建一个配置文件config.py<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MONGO_URL = &apos;localhost&apos;</span><br><span class="line">MONGO_DB = &apos;toutiao&apos;</span><br><span class="line">MONGO_TABLE = &apos;toutiao&apos;</span><br><span class="line"></span><br><span class="line">GROUT_START = 1</span><br><span class="line">GROUP_END = 40</span><br><span class="line"></span><br><span class="line">KEYWORD = &apos;街拍&apos;</span><br></pre></td></tr></table></figure></p><p>然后在使用mongo的时候调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 生成mongodb数据库对象</span><br><span class="line">client = pymongo.MongoClient(MONGO_URL,connect=False)</span><br><span class="line">db = client[MONGO_DB]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_to_mongo(result):</span><br><span class="line">    if db[MONGO_TABLE].insert(result):</span><br><span class="line">        print(&quot;存储到mongodb成功&quot;, result)</span><br><span class="line">        return True</span><br><span class="line">    return False</span><br></pre></td></tr></table></figure></p><p>图片下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def download_image(url):</span><br><span class="line">    print(&quot;正在下载&quot;, url)</span><br><span class="line">    try:</span><br><span class="line">        response = requests.get(url=url, headers=headers)</span><br><span class="line">        if response.status_code == 200:</span><br><span class="line">            save_image(response.content)</span><br><span class="line">        return None</span><br><span class="line">    except RequestException as e:</span><br><span class="line">        print(e)</span><br><span class="line">        print(&quot;请求图片出错&quot;, url)</span><br><span class="line">        return None</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_image(content):</span><br><span class="line">    file_path = &apos;&#123;0&#125;/&#123;1&#125;.&#123;2&#125;&apos;.format(os.getcwd(), md5(content).hexdigest(), &apos;jpg&apos;)</span><br><span class="line">    if not os.path.exists(file_path):</span><br><span class="line">        with open(file_path, &apos;wb&apos;) as f:</span><br><span class="line">            f.write(content)</span><br></pre></td></tr></table></figure></p><p>下载图片使用md5计算名称，存到当前路径。</p><h3 id="main函数"><a href="#main函数" class="headerlink" title="main函数"></a>main函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def main(offset):</span><br><span class="line">    html = get_page_index(offset, KEYWORD)</span><br><span class="line">    for item in parse_page_index(html):</span><br><span class="line">        print(item)</span><br><span class="line">        html = get_page_detail(item[&apos;url&apos;])</span><br><span class="line">        if html:</span><br><span class="line">            images = parse_page_detail(html)</span><br><span class="line">            save_to_mongo(&#123;</span><br><span class="line">                &apos;title&apos;: item[&apos;title&apos;],</span><br><span class="line">                &apos;url&apos;: item[&apos;url&apos;],</span><br><span class="line">                &apos;images&apos;: images</span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure><p>main函数参数为offset，keyword由配置文件传入。</p><p>main函数逻辑是，获取offset（偏移）后，获取这个json的数据并且解析出每一个item（dict类型，含有url和title），通过get_page_detail解析出每个网页的html，通过parse_page_detail解析出images，并且通过save_to_mongo存储到mongodb。</p><p>在调用parse_page_detail的时候就已经下载了图片。</p><h3 id="运行函数"><a href="#运行函数" class="headerlink" title="运行函数"></a>运行函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    main(offset=20)</span><br></pre></td></tr></table></figure><p>如果要多进程，使用：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    groups = [x * 20 for x in range(GROUT_START, GROUP_END + 1)]</span><br><span class="line">    pool = Pool()</span><br><span class="line">    pool.map(main, groups)</span><br></pre></td></tr></table></figure></p><p>groups为config.py中设置的1-40，groups实际上值为[20,40，60，…,400]。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/snjl/python.spider.jiepai.git&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/snjl/python.spider.jiep
      
    
    </summary>
    
      <category term="爬虫" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
      <category term="案例" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/%E6%A1%88%E4%BE%8B/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="案例" scheme="https://snjl.github.io/tags/%E6%A1%88%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>anaconda安装后为3.7版本，修改为3.6</title>
    <link href="https://snjl.github.io/2019/02/03/anaconda%E5%AE%89%E8%A3%85%E5%90%8E%E4%B8%BA3.7%E7%89%88%E6%9C%AC%EF%BC%8C%E4%BF%AE%E6%94%B9%E4%B8%BA3.6/"/>
    <id>https://snjl.github.io/2019/02/03/anaconda安装后为3.7版本，修改为3.6/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:03:09.143Z</updated>
    
    <content type="html"><![CDATA[<p>在安装anaconda后，python版本为3.7，由于很多包不支持或者支持效果不好（例如TensorFlow等），所以要降到3.6版本由于使用shell命令使用anaconda创建的环境可能出现问题，所以要在base环境下安装python3.6，可以使用以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install python=3.6</span><br></pre></td></tr></table></figure><p>安装完成后，使用python（或者python3）命令打开python3.6.8，使用pip（不是pip3）可以直接进行包管理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在安装anaconda后，python版本为3.7，由于很多包不支持或者支持效果不好（例如TensorFlow等），所以要降到3.6版本由于使用shell命令使用anaconda创建的环境可能出现问题，所以要在base环境下安装python3.6，可以使用以下命令：&lt;/p&gt;
      
    
    </summary>
    
      <category term="爬虫" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="anaconda" scheme="https://snjl.github.io/tags/anaconda/"/>
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>mongodb配置</title>
    <link href="https://snjl.github.io/2019/02/03/mongdb%E9%85%8D%E7%BD%AE/"/>
    <id>https://snjl.github.io/2019/02/03/mongdb配置/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:01:13.345Z</updated>
    
    <content type="html"><![CDATA[<h1 id="windows安装"><a href="#windows安装" class="headerlink" title="windows安装"></a>windows安装</h1><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>官网下载。</p><h2 id="配置数据库路径"><a href="#配置数据库路径" class="headerlink" title="配置数据库路径"></a>配置数据库路径</h2><p>下载安装mongo后，在server的版本路径地址下添加文件夹data，data内建立文件夹db，用来存储mongo的配置文件和数据库：</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup1.png" alt="image"></p><p>之后在bin路径下打开cmd或cmder（管理员权限），输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongod --dbpath &quot;C:\Program Files\MongoDB\Server\3.4\data\db&quot;</span><br></pre></td></tr></table></figure></p><p>即使用mongod命令指定db的路径，如下所示，在浏览器中输入localhost:27017(mongo默认端口)看到显示就是配置正确：</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup2.png" alt="image"></p><p>开启另一个命令行，在bin路径下输入mongo即可进入数据库：</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup3.png" alt="image"></p><h2 id="配置mongo系统服务："><a href="#配置mongo系统服务：" class="headerlink" title="配置mongo系统服务："></a>配置mongo系统服务：</h2><p>进入server文件夹-3.4-data，创建logs文件夹，里面创建mongo.log日志文件，然后在bin文件夹中，使用管理员的cmd中输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongod --bind_ip 0.0.0.0 --logpath &quot;C:\Program Files\MongoDB\Server\3.4\data\logs\mongo.log&quot; --logappend --dbpath &quot;C:\Program Files\MongoDB\Server\3.4\data\db&quot; --port 27017 --serviceName &quot;MongoDB&quot; --serviceDisplayName &quot;MongoDB&quot; --install</span><br></pre></td></tr></table></figure></p><p>如果mongo的路径中含有空格，一定要加双引号，这里选定了log的路径，且指定为append方式添加日志，指定端口27017，指定服务名称MongoDB，显示名称也是MongoDB。</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup4.png" alt="image"></p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup5.png" alt="image"></p><p>未显示报错即成功。</p><h2 id="查看是否配置成功"><a href="#查看是否配置成功" class="headerlink" title="查看是否配置成功"></a>查看是否配置成功</h2><p>打开计算机的服务，查找Mongo：</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup6.png" alt="image"></p><p>右键启动后，在浏览器输入localhost:27017即可访问，在日志文件也能看到访问信息：</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup7.png" alt="image"></p><h2 id="使用可视化工具"><a href="#使用可视化工具" class="headerlink" title="使用可视化工具"></a>使用可视化工具</h2><p>安装robo 3T，连接localhost的27017端口，如下显示就是连接正确：</p><p><img src="https://raw.githubusercontent.com/snjl/picture/master/db/mongodb/mongo_setup8.png" alt="image"></p><h1 id="linux安装"><a href="#linux安装" class="headerlink" title="linux安装"></a>linux安装</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install mongodb-server</span><br></pre></td></tr></table></figure><h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">snjl@VM-0-2-ubuntu:~$ mongo</span><br><span class="line">MongoDB shell version: 2.6.10</span><br><span class="line">connecting to: test</span><br><span class="line">Welcome to the MongoDB shell.</span><br><span class="line">For interactive help, type &quot;help&quot;.</span><br><span class="line">For more comprehensive documentation, see</span><br><span class="line">        http://docs.mongodb.org/</span><br><span class="line">Questions? Try the support group</span><br><span class="line">        http://groups.google.com/group/mongodb-user</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; use local</span><br><span class="line">switched to db local</span><br><span class="line">&gt; db.test.insert(&#123;&apos;a&apos;:&apos;bb&apos;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line">&gt; db.test.find()</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5c531d6efafa716545110885&quot;), &quot;a&quot; : &quot;bb&quot; &#125;</span><br></pre></td></tr></table></figure><h1 id="远程连接配置"><a href="#远程连接配置" class="headerlink" title="远程连接配置"></a>远程连接配置</h1><p>mongodb远程连接配置如下：</p><h2 id="修改配置文件mongodb-conf"><a href="#修改配置文件mongodb-conf" class="headerlink" title="修改配置文件mongodb.conf"></a>修改配置文件mongodb.conf</h2><p>命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/mongodb.conf</span><br></pre></td></tr></table></figure></p><p>把 bind_ip=127.0.0.1 这一行注释掉或者是修改成 bind_ip=0.0.0.0</p><h2 id="重启mongodb服务"><a href="#重启mongodb服务" class="headerlink" title="重启mongodb服务"></a>重启mongodb服务</h2><p>命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/mongodb restart</span><br></pre></td></tr></table></figure></p><p>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mongodb restart</span><br></pre></td></tr></table></figure></p><h2 id="防火墙开放27017端口"><a href="#防火墙开放27017端口" class="headerlink" title="防火墙开放27017端口"></a>防火墙开放27017端口</h2><p>命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 27017 -j ACCEPT</span><br></pre></td></tr></table></figure></p><h2 id="远程连接"><a href="#远程连接" class="headerlink" title="远程连接"></a>远程连接</h2><p>要连接的IP：134.567.345.23</p><p>命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongo 134.567.345.23:27017</span><br></pre></td></tr></table></figure></p><p>这样就可以连接到134.567.345.23的mongodb/test的数据库</p><h2 id="连接到自定义的用户"><a href="#连接到自定义的用户" class="headerlink" title="连接到自定义的用户"></a>连接到自定义的用户</h2><h3 id="增加"><a href="#增加" class="headerlink" title="增加"></a>增加</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; use admin</span><br><span class="line">switched to db admin</span><br><span class="line">&gt; db.addUser(&apos;username&apos;,&apos;password&apos;)</span><br></pre></td></tr></table></figure><h3 id="远程连接-1"><a href="#远程连接-1" class="headerlink" title="远程连接"></a>远程连接</h3><p>命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mongo 134.567.345.23:27017/admin -uusername -p</span><br></pre></td></tr></table></figure></p><p>输入password即可</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;windows安装&quot;&gt;&lt;a href=&quot;#windows安装&quot; class=&quot;headerlink&quot; title=&quot;windows安装&quot;&gt;&lt;/a&gt;windows安装&lt;/h1&gt;&lt;h2 id=&quot;下载&quot;&gt;&lt;a href=&quot;#下载&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="数据库" scheme="https://snjl.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="mongodb" scheme="https://snjl.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/mongodb/"/>
    
    
      <category term="mongodb" scheme="https://snjl.github.io/tags/mongodb/"/>
    
      <category term="数据库" scheme="https://snjl.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>redis配置</title>
    <link href="https://snjl.github.io/2019/02/03/redis%E9%85%8D%E7%BD%AE/"/>
    <id>https://snjl.github.io/2019/02/03/redis配置/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:01:34.015Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-简介"><a href="#Redis-简介" class="headerlink" title="Redis 简介"></a>Redis 简介</h1><p>Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。</p><p>Redis 与其他 key - value 缓存产品有以下三个特点：</p><ul><li>Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份。<h1 id="Redis-优势"><a href="#Redis-优势" class="headerlink" title="Redis 优势"></a>Redis 优势</h1></li><li>性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。</li><li>丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。</li><li>原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。</li><li>丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。<h1 id="Redis与其他key-value存储有什么不同？"><a href="#Redis与其他key-value存储有什么不同？" class="headerlink" title="Redis与其他key-value存储有什么不同？"></a>Redis与其他key-value存储有什么不同？</h1></li><li><p>Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。</p></li><li><p>Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。</p></li></ul><h1 id="windows"><a href="#windows" class="headerlink" title="windows"></a>windows</h1><p>去菜鸟教程找redis的下载地址（<a href="https://github.com/MSOpenTech/redis/releases），下载msi。之后找redis" target="_blank" rel="noopener">https://github.com/MSOpenTech/redis/releases），下载msi。之后找redis</a> desktop manager下载安装。</p><p>在github上搜redis desktop，安装一个可视化界面：<br><a href="https://github.com/uglide/RedisDesktopManager" target="_blank" rel="noopener">https://github.com/uglide/RedisDesktopManager</a></p><p>默认端口为6379。</p><h1 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install redis-server</span><br></pre></td></tr></table></figure><p>使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">snjl@VM-0-2-ubuntu:~$ redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set &apos;a&apos; &apos;b&apos;</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get &apos;a&apos;</span><br><span class="line">&quot;b&quot;</span><br></pre></td></tr></table></figure></p><p>设置远程连接和密码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/redis/redis.conf</span><br></pre></td></tr></table></figure></p><p>找到里面的bind 127.0.0.1，改为0.0.0.0，找到requirepass，取消注释后把后面的内容修改为密码。</p><p>重启服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service redis restart</span><br></pre></td></tr></table></figure></p><p>这时候登录需要加入密码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -a PASSWORD</span><br></pre></td></tr></table></figure></p><p>此时才可以用get ‘a’获取值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis-简介&quot;&gt;&lt;a href=&quot;#Redis-简介&quot; class=&quot;headerlink&quot; title=&quot;Redis 简介&quot;&gt;&lt;/a&gt;Redis 简介&lt;/h1&gt;&lt;p&gt;Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。&lt;/p
      
    
    </summary>
    
      <category term="数据库" scheme="https://snjl.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="redis" scheme="https://snjl.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/"/>
    
    
      <category term="数据库" scheme="https://snjl.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="redis" scheme="https://snjl.github.io/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>requests+BeautifulSoup爬取猫眼电影</title>
    <link href="https://snjl.github.io/2019/02/03/requests+BeautifulSoup%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1/"/>
    <id>https://snjl.github.io/2019/02/03/requests+BeautifulSoup爬取猫眼电影/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:02:30.303Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><p>提取的站点URL为<a href="http://maoyan.com/board/4，提取的结果会以文件形式保存下来。" target="_blank" rel="noopener">http://maoyan.com/board/4，提取的结果会以文件形式保存下来。</a></p><h1 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h1><p>分为几个部分，分别是：</p><ul><li>获取单个网页的内容，解析单个网页；</li><li>解析整个网页多个项目，并且每个项目返回dict（使用field）；</li><li>存储数据；</li><li>生成需要爬取的多个网页，并且调用上述函数进行爬取和存储。</li></ul><h2 id="获取单个网页内容"><a href="#获取单个网页内容" class="headerlink" title="获取单个网页内容"></a>获取单个网页内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def get_one_page(url, headers):</span><br><span class="line">    try:</span><br><span class="line"></span><br><span class="line">        response = requests.get(url=url, headers=headers)</span><br><span class="line">        if response.status_code == 200:</span><br><span class="line">            return response.text</span><br><span class="line">        return None</span><br><span class="line">    except RequestException as e:</span><br><span class="line">        print(e)</span><br><span class="line">        return None</span><br></pre></td></tr></table></figure><p>传入url和headers，使用异常类进行捕获。</p><h2 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def parse_one_page(html):</span><br><span class="line">    bs_obj = BeautifulSoup(html)</span><br><span class="line">    items = bs_obj.find_all(&quot;dd&quot;)</span><br><span class="line">    for item in items:</span><br><span class="line">        yield &#123;</span><br><span class="line">            &apos;img&apos;: item.find(&apos;img&apos;, &#123;&apos;class&apos;: &apos;board-img&apos;&#125;).get(&apos;data-src&apos;),</span><br><span class="line">            &apos;title&apos;: item.find(&apos;p&apos;, &#123;&apos;class&apos;: &apos;name&apos;&#125;).find(&apos;a&apos;).get(&apos;title&apos;).strip(),</span><br><span class="line">            &apos;stars&apos;: item.find(&apos;p&apos;, &#123;&apos;class&apos;: &apos;star&apos;&#125;).text.strip(),</span><br><span class="line">            &apos;time&apos;: item.find(&apos;p&apos;, &#123;&apos;class&apos;: &apos;releasetime&apos;&#125;).text.strip(),</span><br><span class="line">            &apos;score&apos;: item.find(&apos;i&apos;, &#123;&apos;class&apos;: &apos;integer&apos;&#125;).text + item.find(&apos;i&apos;, &#123;&apos;class&apos;: &apos;fraction&apos;&#125;).text</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>分析网页可以知道dd标签分割每个项目，将单个项目拿出来，使用BeautifulSoup进行解析，使用yield返回数据。</p><h2 id="文件写入"><a href="#文件写入" class="headerlink" title="文件写入"></a>文件写入</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">def write_to_file(content):</span><br><span class="line">    with open(&apos;result.txt&apos;, &apos;a&apos;, encoding=&apos;utf8&apos;) as f:</span><br><span class="line">        f.write(json.dumps(content, ensure_ascii=False) + &apos;\n&apos;)</span><br></pre></td></tr></table></figure><p>使用with，可以保证异常关闭；使用a，可以保证写入不清空；使用utf8和json存储时的ensure_ascii=False，可以使写入数据为utf8编码。</p><h2 id="翻页爬取"><a href="#翻页爬取" class="headerlink" title="翻页爬取"></a>翻页爬取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def main(offset):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &apos;user-agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &apos;</span><br><span class="line">                      &apos;Chrome/71.0.3578.98 Safari/537.36&apos;</span><br><span class="line">    &#125;</span><br><span class="line">    url = &apos;https://maoyan.com/board/4?offset=&apos; + str(offset)</span><br><span class="line"></span><br><span class="line">    html = get_one_page(url, headers)</span><br><span class="line">    for item in parse_one_page(html):</span><br><span class="line">        print(item)</span><br><span class="line">        write_to_file(item)</span><br></pre></td></tr></table></figure><p>跳转页面，可以发现网址从<a href="http://maoyan.com/board/4变为了http://maoyan.com/board/4?offset=10。" target="_blank" rel="noopener">http://maoyan.com/board/4变为了http://maoyan.com/board/4?offset=10。</a></p><p>比之前的URL多了一个参数，那就是offset=10，而目前显示的结果是排行11~20名的电影，初步推断这是一个偏移量的参数。再点击下一页，发现页面的URL变成了<a href="http://maoyan.com/board/4?offset=20，参数offset变成了20，而显示的结果是排行21~30的电影。" target="_blank" rel="noopener">http://maoyan.com/board/4?offset=20，参数offset变成了20，而显示的结果是排行21~30的电影。</a></p><p>由此可以总结出规律，offset代表偏移量值，如果偏移量为n，则显示的电影序号就是n+1到n+10，每页显示10个。所以，如果想获取TOP100电影，只需要分开请求10次，而10次的offset参数分别设置为0、10、20、…90即可，这样获取不同的页面之后，再用正则表达式提取出相关信息，就可以得到TOP100的所有电影信息了。</p><h2 id="main方法"><a href="#main方法" class="headerlink" title="main方法"></a>main方法</h2><p>最后，实现main()方法来调用前面实现的方法，将单页的电影结果写入到文件。相关代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    for i in range(10):</span><br><span class="line">        main(i*10)</span><br></pre></td></tr></table></figure></p><p>如果需要考虑爬虫过快，可以在后面加一个sleep：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    for i in range(10):</span><br><span class="line">        main(i*10)</span><br><span class="line">        time.sleep(1)</span><br></pre></td></tr></table></figure></p><h1 id="使用多进程"><a href="#使用多进程" class="headerlink" title="使用多进程"></a>使用多进程</h1><p>将main的代码改成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line"></span><br><span class="line">    # 使用多进程</span><br><span class="line">    pool = Pool()</span><br><span class="line">    pool.map(main, [i * 10 for i in range(10)])</span><br></pre></td></tr></table></figure></p><p>引入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br></pre></td></tr></table></figure></p><p>如果使用多进程，想要防止爬虫过快，可以在main函数里加一个sleep<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def main(offset):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &apos;user-agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &apos;</span><br><span class="line">                      &apos;Chrome/71.0.3578.98 Safari/537.36&apos;</span><br><span class="line">    &#125;</span><br><span class="line">    url = &apos;https://maoyan.com/board/4?offset=&apos; + str(offset)</span><br><span class="line"></span><br><span class="line">    html = get_one_page(url, headers)</span><br><span class="line">    for item in parse_one_page(html):</span><br><span class="line">        print(item)</span><br><span class="line">        write_to_file(item)</span><br><span class="line">    time.sleep(1)</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h1&gt;&lt;p&gt;提取的站点URL为&lt;a href=&quot;http://maoyan.com/board/4，提取的结果会以文件形式保存下来。&quot; target=&quot;
      
    
    </summary>
    
      <category term="爬虫" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
      <category term="案例" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/%E6%A1%88%E4%BE%8B/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="案例" scheme="https://snjl.github.io/tags/%E6%A1%88%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>flask：hello world</title>
    <link href="https://snjl.github.io/2019/02/03/flask%EF%BC%9Ahello%20world/"/>
    <id>https://snjl.github.io/2019/02/03/flask：hello world/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T15:59:43.605Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/snjl/python.flask.helloworld.git" target="_blank" rel="noopener">https://github.com/snjl/python.flask.helloworld.git</a></p><h1 id="flask优点"><a href="#flask优点" class="headerlink" title="flask优点"></a>flask优点</h1><ul><li>Flask确实很“轻”，不愧是Micro Framework，从Django转向Flask的开发者一定会如此感慨，除非二者均未深入使用过</li><li>Flask自由、灵活，可扩展性强，第三方库的选择面广，开发时可以结合自己最喜欢用的轮子，也能结合最流行最强大的Python库</li><li>入门简单，即便没有多少web开发经验，也能很快做出网站</li><li>非常适用于小型网站</li><li>非常适用于开发web服务的API</li><li>开发大型网站无压力，但代码架构需要自己设计，开发成本取决于开发者的能力和经验</li><li>各方面性能均等于或优于Django</li><li>Django自带的或第三方的好评如潮的功能，Flask上总会找到与之类似第三方库</li><li>Flask灵活开发，Python高手基本都会喜欢Flask，但对Django却可能褒贬不一</li><li>Flask与关系型数据库的配合使用不弱于Django，而其与NoSQL数据库的配合远远优于Django</li><li>Flask比Django更加Pythonic，与Python的philosophy更加吻合</li></ul><h1 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world"></a>hello world</h1><p>使用pycharm生成一个flask项目，项目结构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">helloworld</span><br><span class="line">    static</span><br><span class="line">    templates</span><br><span class="line">    helloworld.py</span><br></pre></td></tr></table></figure></p><p>其中helloworld.py代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from app import app</span><br><span class="line"></span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">@app.route(&apos;/index&apos;)</span><br><span class="line">def index():</span><br><span class="line">    return &quot;Hello, World!&quot;</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    app.run(debug=True)</span><br></pre></td></tr></table></figure></p><p>使用app.run(debug=True)，可以直接在pycharm中跑，而且这样在修改网页模版的时候，刷新网页内容会直接更新。</p><p>这个视图函数其实很简单，这是返回了这个 Hello, World! 字符串。在函数定义上面的是两个装饰器，Python 中特别的语法糖。装饰器改变或者增加了被装饰函数的功能。一个装饰器经常会用到的地方是将函数注册为某些事件的回调函数。在这里，@app.route 装饰器创建了以参数给定的 URL 和视图函数的联系。这里有两个装饰器，将 / 和 /index 和 index 函数关联起来了。这意味着，不论 web 浏览器向哪个 URL 发送请求，Flask 将会调用这个函数，然后将返回值作为对浏览器的响应。</p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; set FLASK_APP=run.py </span><br><span class="line">&gt; flask run</span><br><span class="line"> * Running on http://127.0.0.1:5000/</span><br></pre></td></tr></table></figure><p>函数写成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from app import app</span><br><span class="line"></span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">@app.route(&apos;/index&apos;)</span><br><span class="line">def index():</span><br><span class="line">    return &quot;Hello, World!&quot;</span><br></pre></td></tr></table></figure></p><p>在服务器初始化完成之后，它就在等待来自客户端的链接了。flask run 的输出表示服务器正在运行在 127.0.0.1 这个 IP 地址上，这个总是你本机的地址。这个地址很常用，因此有一个更简单的别名: localhost。服务器会监听特定的端口，在生产环境上的服务器一般会监听 443 端口，或者在不需要加密的时候使用 80 端口，但是这些都需要管理员权限。因为应用在开发环境上运行，Flask 使用了可用的 5000 端口。下面在浏览器中输入下面的 URL：<a href="http://localhost:5000/，当然你也可以输入下面这个" target="_blank" rel="noopener">http://localhost:5000/，当然你也可以输入下面这个</a>: <a href="http://localhost:5000/index" target="_blank" rel="noopener">http://localhost:5000/index</a></p><p>两个不同的 URL 会返回同样的东西。但是你输入其他 URL 将会发生一个 404 错误，因为只有上面两个 URL 可以被应用识别。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://github.com/snjl/python.flask.helloworld.git&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/snjl/python.flask.hellowo
      
    
    </summary>
    
      <category term="flask" scheme="https://snjl.github.io/categories/flask/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="flask" scheme="https://snjl.github.io/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>flask：模版</title>
    <link href="https://snjl.github.io/2019/02/03/flask%EF%BC%9A%E6%A8%A1%E7%89%88/"/>
    <id>https://snjl.github.io/2019/02/03/flask：模版/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:34:37.856Z</updated>
    
    <content type="html"><![CDATA[<p>项目地址：<a href="https://github.com/snjl/python.flask.templates.git" target="_blank" rel="noopener">https://github.com/snjl/python.flask.templates.git</a></p><h1 id="什么是模板"><a href="#什么是模板" class="headerlink" title="什么是模板?"></a>什么是模板?</h1><p>我想要我的首页头部有一个欢迎用户的显示。当然现在应用中还没有用户的概念，在后面会加上。取而代之的是，我将会使用一个 mock 用户(模拟用户)，我用一个 Python 字典来实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">user = &#123;&apos;username&apos;: &apos;snjl&apos;&#125;</span><br></pre></td></tr></table></figure></p><p>创建一些模拟对象是一项比较有用的技术，这样使得你能专心于应用的一部分，而不用担心系统的其他部分还不存在。我想为我的应用设计一个首页，但是我不想被系统目前没有用户系统而烦恼，因此我模拟了一个用户对象，这样我就可以继续我的工作了。</p><p>视图函数返回了一个简单的字符串。我要做的就是将这个返回的字符串展开成一个完整的 HTML 页面。比如这样：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from flask import Flask</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">@app.route(&apos;/index&apos;)</span><br><span class="line">def index():</span><br><span class="line">    user = &#123;&apos;username&apos;: &apos;snjl&apos;&#125;</span><br><span class="line">    return &apos;&apos;&apos;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">        &lt;title&gt;Home Page - Home&lt;/title&gt;</span><br><span class="line">    &lt;/head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        &lt;h1&gt;Hello, &apos;&apos;&apos; + user[&apos;username&apos;] + &apos;&apos;&apos;!&lt;/h1&gt;</span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    app.run(debug=True)</span><br></pre></td></tr></table></figure></p><h1 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h1><p>上述将 HTML 传递到浏览器的方式不是很好。当我想将用户的文章返回的时候，视图函数将会变得复杂，而且文章还会经常改变。而且应用还会有与其他 URL 绑定的视图函数，那么想象以下将来有一天我要改变应用的布局，那么我就得在每个视图函数中更新 HTML。所以这绝不是一个应对应用规模不断增长的方案。</p><p>如果能将应用的逻辑和 web 页面的展示和布局分开的话，所有的东西都变得易于组织，甚至可以雇佣一个 web 页面设计者来创造非常牛逼的页面，而你只需要使用 Python 完成应用的逻辑代码。</p><p>模板帮助实现了表示层和业务逻辑的分离。在 Flask 中，模板被写在单独的文件中，存储在应用的包的 templates 文件夹中。因此确保你在项目文件夹下，创建 templates 文件夹。</p><p>下面你可以看到你的第一个模板，和上面 index() 视图函数返回的 HTML 页面很相似，将这个文件保存在 app/templates/index.html<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">        &lt;title&gt;&#123;&#123; title &#125;&#125; - Home&lt;/title&gt;</span><br><span class="line">    &lt;/head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        &lt;h1&gt;Hello, &#123;&#123; user.username &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p><p>这一个标准的，非常简单的 HTML 页面。里面值得注意的是，两个花括号括起来的用于动态内容的部分。这表示里面的内容是变量，而且之后再运行的时候才能生成。</p><p>现在页面的展示已经放到了 HTML 模板中，视图函数就被简化了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from flask import render_template</span><br><span class="line">from flask import Flask</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">@app.route(&apos;/index&apos;)</span><br><span class="line">def index():</span><br><span class="line">    user = &#123;&apos;username&apos;: &apos;snjl&apos;&#125;</span><br><span class="line">    return render_template(&apos;index.html&apos;, title=&apos;Home&apos;, user=user)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    app.run(debug=True)</span><br></pre></td></tr></table></figure><p>是不是看起来更好了。在应用中试试看看模板是怎么工作的。一旦你在浏览器中载入了这个页面，你可能想看看 HTML 源代码和以前有什么不一样。</p><p>将模板转换成完整的 HTML 页面的过程叫做渲染(rendering)。为了渲染模板，我必须从 Flask 中导入一个函数叫做 render_template，这个函数将模板名字和一个模板参数的变量列表作为参数，然后返回同样的模板，但是已经用变量将模板中的占位符给替换了。</p><p>render_template() 函数调用了 Jinja2 模板引擎，该引擎是和 Flask 绑定在一起的。Jinja2 将会使用通过 render_template 函数传递进来的参数来替代对应的块。</p><h1 id="条件语句"><a href="#条件语句" class="headerlink" title="条件语句"></a>条件语句</h1><p>你已经看到了 Jinja2 在渲染的时候是如何将真实的值替换占位符的，但是这只是 Jinja2 众多强大功能之一。比如，模板同样支持控制语句。index.html 的下一个版本就是增加一个条件语句。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">        &#123;% if title %&#125;</span><br><span class="line">        &lt;title&gt;&#123;&#123; title &#125;&#125; - snjl&lt;/title&gt;</span><br><span class="line">        &#123;% else %&#125;</span><br><span class="line">        &lt;title&gt;Welcome to snjl!&lt;/title&gt;</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    &lt;/head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        &lt;h1&gt;Hello, &#123;&#123; user.username &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>现在模板变得更智能了。如果视图函数忘记传递 title 参数，模板会使用默认值来渲染而不是一个空的 title。你可以通过移除 title 参数来查看条件语句是如何工作的。</p><h1 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h1><p>登录的用户可能想看在首页的所有用户最近的文章列表。那么应该如何扩展应用来支持这个功能呢。</p><p>同样，我会创建一些模拟的用户对象和一些文章对象来展示。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">from flask import render_template</span><br><span class="line">from flask import Flask</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">@app.route(&apos;/index&apos;)</span><br><span class="line">def index():</span><br><span class="line">    user = &#123;&apos;username&apos;: &apos;snjl&apos;&#125;</span><br><span class="line">    posts = [</span><br><span class="line">        &#123;</span><br><span class="line">            &apos;author&apos;: &#123;&apos;username&apos;: &apos;John&apos;&#125;,</span><br><span class="line">            &apos;body&apos;: &apos;Beautiful day in Portland!&apos;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            &apos;author&apos;: &#123;&apos;username&apos;: &apos;Susan&apos;&#125;,</span><br><span class="line">            &apos;body&apos;: &apos;The Avengers movie was so cool!&apos;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">    return render_template(&apos;index_3.html&apos;, title=&apos;Home&apos;, user=user, posts=posts)</span><br><span class="line">    # return render_template(&apos;index_3.html&apos;, user=user, posts=posts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    app.run(debug=True)</span><br></pre></td></tr></table></figure><p>使用了个列表，里面每个元素都是一个字典，并且都包含 author 和 body 字段。当我要实现用户和文章的时候我也会尽量保留现在的字段名字，所以在之后我在设计和测试之中使用的这些对象依然有效。</p><p>在模板方面我必须得解决一个新的问题。posts 列表可能有任意多个元素，它取决于视图函数决定多少个 posts 将会在页面展示。模板不能对有多少 posts 做任何假定，因此它必须以通用的方式来渲染任意视图函数传递给它的 posts。</p><p>对于这个问题，Jinja2 提供了 for 控制结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">        &#123;% if title %&#125;</span><br><span class="line">        &lt;title&gt;&#123;&#123; title &#125;&#125; - snjl&lt;/title&gt;</span><br><span class="line">        &#123;% else %&#125;</span><br><span class="line">        &lt;title&gt;Welcome to snjl&lt;/title&gt;</span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    &lt;/head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        &lt;h1&gt;Hi, &#123;&#123; user.username &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">        &#123;% for post in posts %&#125;</span><br><span class="line">        &lt;div&gt;&lt;p&gt;&#123;&#123; post.author.username &#125;&#125; says: &lt;b&gt;&#123;&#123; post.body &#125;&#125;&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><h1 id="模板继承"><a href="#模板继承" class="headerlink" title="模板继承"></a>模板继承</h1><p>大多数 web 应用在页面顶部都会有一个导航栏，上面放置一些比较常用的链接，比如编辑个人资料，登录登出等。我可以很容易的给 index.html 模板来添加一个导航栏，但是随着应用的规模增长我需要将同样的导航栏放到其他页面上。但是我不想在多个 HTML 模板中维护数个一样的导航栏。not repeat yourself 不要重复你自己！</p><p>Jinja2 拥有模板继承特性就是来解决这个问题的。在本质上，你要做的就是将所有模板共同的东西拿到一个基础模板中，然后其他模板从这个基础模板派生。</p><p>所以我要做的就是定义一个叫 base.html 的基础模板，其包含了一个简单的导航栏以及之前实现的简单逻辑。你需要将下面的代码保存到app/template/base.html 模板中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">    &lt;head&gt;</span><br><span class="line">      &#123;% if title %&#125;</span><br><span class="line">      &lt;title&gt;&#123;&#123; title &#125;&#125; - Microblog&lt;/title&gt;</span><br><span class="line">      &#123;% else %&#125;</span><br><span class="line">      &lt;title&gt;Welcome to Microblog&lt;/title&gt;</span><br><span class="line">      &#123;% endif %&#125;</span><br><span class="line">    &lt;/head&gt;</span><br><span class="line">    &lt;body&gt;</span><br><span class="line">        &lt;div&gt;Microblog: &lt;a href=&quot;/index&quot;&gt;Home&lt;/a&gt;&lt;/div&gt;</span><br><span class="line">        &lt;hr&gt;</span><br><span class="line">        &#123;% block content %&#125;&#123;% endblock %&#125;</span><br><span class="line">    &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p><p>在这个模板中我使用了 block 控制语句来定义派生模板可以插入的位置。block 的名字是唯一的，这样派生模板就可以在提供他们的内容时候引用。</p><p>在有了基础模板，我现在可以让 index.html 来继承 base.html<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;% extends &quot;base.html&quot; %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% block content %&#125;</span><br><span class="line">    &lt;h1&gt;Hi, &#123;&#123; user.username &#125;&#125;!&lt;/h1&gt;</span><br><span class="line">    &#123;% for post in posts %&#125;</span><br><span class="line">    &lt;div&gt;&lt;p&gt;&#123;&#123; post.author.username &#125;&#125; says: &lt;b&gt;&#123;&#123; post.body &#125;&#125;&lt;/b&gt;&lt;/p&gt;&lt;/div&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&#123;% endblock %&#125;</span><br></pre></td></tr></table></figure></p><p>既然 base.html 现在可以承担通用的页面结构，我将这些元素从 index.html 中移除了，只留下了内容部分。extends 语句在两个模板间建立了继承关系，因此 Jinja2 知道当要渲染 index.html 的时候，需要将其嵌入到 base.html。两个模板会来用名字 content 来匹配 block 语句，这也是 Jinja2 为什么知道如何将两个模板合并成一个。现在如果我需要为应用创建其他页面的话，我可以从同样的 base.html 来派生模板，这也是我可以使得应用的所有页面都看起来相似但是又不会感觉到重复。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/snjl/python.flask.templates.git&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/snjl/python.flask.tem
      
    
    </summary>
    
      <category term="flask" scheme="https://snjl.github.io/categories/flask/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="flask" scheme="https://snjl.github.io/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>flask：运行</title>
    <link href="https://snjl.github.io/2019/02/03/flask%EF%BC%9A%E8%BF%90%E8%A1%8C/"/>
    <id>https://snjl.github.io/2019/02/03/flask：运行/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:00:28.634Z</updated>
    
    <content type="html"><![CDATA[<p>官方文档中，新版本的 Flask(&gt;=0.11) 运行方式和以前有所不同，但是按照官方文档，可能会碰到坑的地方：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: Could not locate Flask application. You did not provide the FLASK_APP environment variable.</span><br></pre></td></tr></table></figure></p><p>问题出在终端上面：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># run.py</span><br><span class="line">from flask import Flask</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">@app.route(&quot;/&quot;)</span><br><span class="line">def hello():</span><br><span class="line">    return &quot;Hello World!&quot;</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    app.run(debug=True)</span><br></pre></td></tr></table></figure></p><h1 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h1><p>运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ export FLASK_APP=run.py</span><br><span class="line">$ flask run</span><br><span class="line"> * Running on http://127.0.0.1:5000/</span><br></pre></td></tr></table></figure></p><h1 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h1><p>如果你的 Terminal 用的是 cmd，那么运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; set FLASK_APP=run.py </span><br><span class="line">&gt; flask run</span><br><span class="line"> * Running on http://127.0.0.1:5000/</span><br></pre></td></tr></table></figure></p><p>如果你的 Terminal 用的是 powershell，那么运行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> &gt; $env:FLASK_APP=&quot;.\run.py&quot; | flask run</span><br><span class="line">* Running on http://127.0.0.1:5000/</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;官方文档中，新版本的 Flask(&amp;gt;=0.11) 运行方式和以前有所不同，但是按照官方文档，可能会碰到坑的地方：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c
      
    
    </summary>
    
      <category term="flask" scheme="https://snjl.github.io/categories/flask/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="flask" scheme="https://snjl.github.io/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>linux python多版本共存</title>
    <link href="https://snjl.github.io/2019/02/03/linux%20python%E5%A4%9A%E7%89%88%E6%9C%AC%E5%85%B1%E5%AD%98/"/>
    <id>https://snjl.github.io/2019/02/03/linux python多版本共存/</id>
    <published>2019-02-03T06:26:13.000Z</published>
    <updated>2019-02-03T16:00:45.905Z</updated>
    
    <content type="html"><![CDATA[<p>输出环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">snjl@VM-0-2-ubuntu:~$ echo $PATH</span><br><span class="line">/home/snjl/bin:/home/snjl/.local/bin:home/snjl/anaconda3/bin:/home/snjl/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin</span><br></pre></td></tr></table></figure></p><p>使用whereis查看目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">snjl@VM-0-2-ubuntu:~$ whereis python2</span><br><span class="line">python2: /usr/bin/python2.7 /usr/bin/python2 /usr/lib/python2.7 /etc/python2.7 /usr/local/lib/python2.7 /usr/share/man/man1/python2.1.gz</span><br><span class="line">snjl@VM-0-2-ubuntu:~$ whereis python3</span><br><span class="line">python3: /usr/bin/python3.5 /usr/bin/python3 /usr/bin/python3.5m /usr/lib/python3.5 /usr/lib/python3 /etc/python3.5 /etc/python3 /usr/local/lib/python3.5 /usr/share/python3 /home/snjl/anaconda3/bin/python3.7-config /home/snjl/anaconda3/bin/python3 /home/snjl/anaconda3/bin/python3.7m-config /home/snjl/anaconda3/bin/python3.7 /home/snjl/anaconda3/bin/python3.7m /usr/share/man/man1/python3.1.gz</span><br><span class="line">snjl@VM-0-2-ubuntu:~$</span><br></pre></td></tr></table></figure></p><p>创建软链接：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -s /usr/bin/python3.5 /user/bin/python3</span><br></pre></td></tr></table></figure></p><p>这样可以直接调用python3，不用调用python3.5。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;输出环境变量&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;b
      
    
    </summary>
    
      <category term="服务器" scheme="https://snjl.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="linux" scheme="https://snjl.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>scrapy管道</title>
    <link href="https://snjl.github.io/2019/01/31/scrapy%E7%AE%A1%E9%81%93/"/>
    <id>https://snjl.github.io/2019/01/31/scrapy管道/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T06:32:09.013Z</updated>
    
    <content type="html"><![CDATA[<p>参考项目：<a href="https://github.com/snjl/python.spider.scrapy_test.git" target="_blank" rel="noopener">https://github.com/snjl/python.spider.scrapy_test.git</a></p><h1 id="Item-Pipeline"><a href="#Item-Pipeline" class="headerlink" title="Item Pipeline"></a>Item Pipeline</h1><p>当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。</p><p>每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。</p><p>以下是item pipeline的一些典型应用：</p><ul><li>清理HTML数据</li><li>验证爬取的数据(检查item包含某些字段)</li><li>查重(并丢弃)</li><li>将爬取结果保存到数据库中<a id="more"></a></li></ul><h1 id="编写你自己的item-pipeline"><a href="#编写你自己的item-pipeline" class="headerlink" title="编写你自己的item pipeline"></a>编写你自己的item pipeline</h1><p><strong>每个item pipiline组件是一个独立的Python类，同时必须实现以下方法:</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">process_item(self, item, spider)</span><br></pre></td></tr></table></figure></p><p>每个item pipeline组件都需要调用该方法，这个方法必须返回一个具有数据的dict，或是 Item (或任何继承类)对象， 或是抛出 DropItem 异常，被丢弃的item将不会被之后的pipeline组件所处理。</p><h2 id="参数"><a href="#参数" class="headerlink" title="参数:"></a>参数:</h2><ul><li>item (Item 对象或者一个dict) – 被爬取的item</li><li>spider (Spider 对象) – 爬取该item的spider<br>此外,他们也可以实现以下方法:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open_spider(self, spider)</span><br></pre></td></tr></table></figure></li></ul><p>当spider被开启时，这个方法被调用。</p><p>参数:    spider (Spider 对象) – 被开启的spider<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">close_spider(self, spider)</span><br></pre></td></tr></table></figure></p><p>当spider被关闭时，这个方法被调用</p><p>参数:    spider (Spider 对象) – 被关闭的spider<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from_crawler(cls, crawler)</span><br></pre></td></tr></table></figure></p><p>类方法，获取scrapy中的一些参数和设置等，例如可以拿到settings.py中的配置信息。</p><p>参数:    crawler (Crawler object) – 使用该管道的爬虫</p><h1 id="Item-pipeline-样例"><a href="#Item-pipeline-样例" class="headerlink" title="Item pipeline 样例"></a>Item pipeline 样例</h1><p>验证价格，同时丢弃没有价格的item<br>让我们来看一下以下这个假设的pipeline，它为那些不含税(price_excludes_vat 属性)的item调整了 price 属性，同时丢弃了那些没有价格的item:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.exceptions import DropItem</span><br><span class="line"></span><br><span class="line">class PricePipeline(object):</span><br><span class="line"></span><br><span class="line">    vat_factor = 1.15</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        if item[&apos;price&apos;]:</span><br><span class="line">            if item[&apos;price_excludes_vat&apos;]:</span><br><span class="line">                item[&apos;price&apos;] = item[&apos;price&apos;] * self.vat_factor</span><br><span class="line">            return item</span><br><span class="line">        else:</span><br><span class="line">            raise DropItem(&quot;Missing price in %s&quot; % item)</span><br></pre></td></tr></table></figure></p><h1 id="将item写入JSON文件"><a href="#将item写入JSON文件" class="headerlink" title="将item写入JSON文件"></a>将item写入JSON文件</h1><p>以下pipeline将所有(从所有spider中)爬取到的item，存储到一个独立地 items.jl 文件，每行包含一个序列化为JSON格式的item:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line">class JsonWriterPipeline(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.file = open(&apos;items.jl&apos;, &apos;wb&apos;)</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        line = json.dumps(dict(item)) + &quot;\n&quot;</span><br><span class="line">        self.file.write(line)</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure></p><h1 id="将item写入MongoDB"><a href="#将item写入MongoDB" class="headerlink" title="将item写入MongoDB"></a>将item写入MongoDB</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import pymongo</span><br><span class="line"></span><br><span class="line">class MongoPipeline(object):</span><br><span class="line"></span><br><span class="line">    collection_name = &apos;scrapy_items&apos;</span><br><span class="line"></span><br><span class="line">    def __init__(self, mongo_uri, mongo_db):</span><br><span class="line">        self.mongo_uri = mongo_uri</span><br><span class="line">        self.mongo_db = mongo_db</span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    def from_crawler(cls, crawler):</span><br><span class="line">        return cls(</span><br><span class="line">            mongo_uri=crawler.settings.get(&apos;MONGO_URI&apos;),</span><br><span class="line">            mongo_db=crawler.settings.get(&apos;MONGO_DATABASE&apos;, &apos;items&apos;)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        self.client = pymongo.MongoClient(self.mongo_uri)</span><br><span class="line">        self.db = self.client[self.mongo_db]</span><br><span class="line"></span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        self.db[self.collection_name].insert(dict(item))</span><br><span class="line">        return item</span><br></pre></td></tr></table></figure><h1 id="去重（Duplicates-filter）"><a href="#去重（Duplicates-filter）" class="headerlink" title="去重（Duplicates filter）"></a>去重（Duplicates filter）</h1><p>一个用于去重的过滤器，丢弃那些已经被处理过的item。让我们假设我们的item有一个唯一的id，但是我们spider返回的多个item中包含有相同的id:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from scrapy.exceptions import DropItem</span><br><span class="line"></span><br><span class="line">class DuplicatesPipeline(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.ids_seen = set()</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        if item[&apos;id&apos;] in self.ids_seen:</span><br><span class="line">            raise DropItem(&quot;Duplicate item found: %s&quot; % item)</span><br><span class="line">        else:</span><br><span class="line">            self.ids_seen.add(item[&apos;id&apos;])</span><br><span class="line">            return item</span><br></pre></td></tr></table></figure></p><h1 id="启用一个Item-Pipeline组件"><a href="#启用一个Item-Pipeline组件" class="headerlink" title="启用一个Item Pipeline组件"></a>启用一个Item Pipeline组件</h1><p>为了启用一个Item Pipeline组件，你必须将它的类添加到 ITEM_PIPELINES 配置，就像下面这个例子:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    &apos;myproject.pipelines.PricePipeline&apos;: 300,</span><br><span class="line">    &apos;myproject.pipelines.JsonWriterPipeline&apos;: 800,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内。</p><h1 id="管道开启、关闭时间等测试"><a href="#管道开启、关闭时间等测试" class="headerlink" title="管道开启、关闭时间等测试"></a>管道开启、关闭时间等测试</h1><p>一共三个管道，在2个管道加入日志输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># MongoDB存储数据管道</span><br><span class="line">class MongoPipeline(object):</span><br><span class="line">    def __init__(self, mongo_uri, mongo_db):</span><br><span class="line">        self.mongo_uri = mongo_uri</span><br><span class="line">        self.mongo_db = mongo_db</span><br><span class="line"></span><br><span class="line">    # 从settings中拿到配置</span><br><span class="line">    @classmethod</span><br><span class="line">    def from_crawler(cls, crawler):</span><br><span class="line">        return cls(</span><br><span class="line">            mongo_uri=crawler.settings.get(&apos;MONGO_URI&apos;),</span><br><span class="line">            mongo_db=crawler.settings.get(&apos;MONGO_DB&apos;)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    # 爬虫启动时需要进行的操作，初始化MongoDB对象</span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        self.client = pymongo.MongoClient(self.mongo_uri)</span><br><span class="line">        self.db = self.client[self.mongo_db]</span><br><span class="line">        spider.logger.info(&quot;mongodb start!&quot;)</span><br><span class="line">    # 最重要的process_item</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        # 使用这样的name比较灵活</span><br><span class="line">        name = item.__class__.__name__</span><br><span class="line">        self.db[name].insert(dict(item))</span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line">    # 管道完毕时自动运行</span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.client.close()</span><br><span class="line">        spider.logger.info(&quot;mongodb close!&quot;)</span><br><span class="line"></span><br><span class="line">class JsonWriterPipeline(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.file = open(&apos;items.jl&apos;, &apos;a+&apos;)</span><br><span class="line">        print(&quot;file open!&quot;)</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        line = json.dumps(dict(item)) + &quot;\n&quot;</span><br><span class="line">        self.file.write(line)</span><br><span class="line">        return item</span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.file.close()</span><br><span class="line">        spider.logger.info(&quot;file close!&quot;)</span><br></pre></td></tr></table></figure></p><p>在输出时候，日志如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">···</span><br><span class="line">2019-01-28 19:36:55 [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">[&apos;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&apos;,</span><br><span class="line"> &apos;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&apos;,</span><br><span class="line"> &apos;scrapy.spidermiddlewares.referer.RefererMiddleware&apos;,</span><br><span class="line"> &apos;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&apos;,</span><br><span class="line"> &apos;scrapy.spidermiddlewares.depth.DepthMiddleware&apos;]</span><br><span class="line">file open!</span><br><span class="line">2019-01-28 19:36:55 [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[&apos;tutorial.pipelines.TutorialPipeline&apos;,</span><br><span class="line"> &apos;tutorial.pipelines.MongoPipeline&apos;,</span><br><span class="line"> &apos;tutorial.pipelines.JsonWriterPipeline&apos;]</span><br><span class="line">2019-01-28 19:36:55 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2019-01-28 19:36:55 [quotes] INFO: mongodb start!</span><br><span class="line">···</span><br><span class="line"># 中间为其他日志记录，例如输出内容和debug等</span><br><span class="line">···</span><br><span class="line">2019-01-28 19:36:59 [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line">2019-01-28 19:36:59 [quotes] INFO: file close!</span><br><span class="line">2019-01-28 19:36:59 [quotes] INFO: mongodb close!</span><br><span class="line">2019-01-28 19:36:59 [scrapy.extensions.feedexport] INFO: Stored jl feed (100 items) in:  quotes1.jl</span><br><span class="line">···</span><br></pre></td></tr></table></figure></p><p>可以看出，管道是爬虫开始前就打开，爬虫结束后关闭，而且在类的<strong>init</strong>函数中的初始化效果和open_spider的初始化效果其实是一样的，因为只开启一次，而不是每次爬取每次都开启，所以效果等同。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考项目：&lt;a href=&quot;https://github.com/snjl/python.spider.scrapy_test.git&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/snjl/python.spider.scrapy_test.git&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;Item-Pipeline&quot;&gt;&lt;a href=&quot;#Item-Pipeline&quot; class=&quot;headerlink&quot; title=&quot;Item Pipeline&quot;&gt;&lt;/a&gt;Item Pipeline&lt;/h1&gt;&lt;p&gt;当Item在Spider中被收集之后，它将会被传递到Item Pipeline，一些组件会按照一定的顺序执行对Item的处理。&lt;/p&gt;
&lt;p&gt;每个item pipeline组件(有时称之为“Item Pipeline”)是实现了简单方法的Python类。他们接收到Item并通过它执行一些行为，同时也决定此Item是否继续通过pipeline，或是被丢弃而不再进行处理。&lt;/p&gt;
&lt;p&gt;以下是item pipeline的一些典型应用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;清理HTML数据&lt;/li&gt;
&lt;li&gt;验证爬取的数据(检查item包含某些字段)&lt;/li&gt;
&lt;li&gt;查重(并丢弃)&lt;/li&gt;
&lt;li&gt;将爬取结果保存到数据库中
    
    </summary>
    
      <category term="scrapy" scheme="https://snjl.github.io/categories/scrapy/"/>
    
      <category term="爬虫" scheme="https://snjl.github.io/categories/scrapy/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="爬虫" scheme="https://snjl.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="scrapy" scheme="https://snjl.github.io/tags/scrapy/"/>
    
  </entry>
  
  <entry>
    <title>文件读写</title>
    <link href="https://snjl.github.io/2019/01/31/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/"/>
    <id>https://snjl.github.io/2019/01/31/文件读写/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:18:35.345Z</updated>
    
    <content type="html"><![CDATA[<p>读写文件是最常见的IO操作。Python内置了读写文件的函数，用法和C是兼容的。</p><p>读写文件前，我们先必须了解一下，在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，所以，读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），然后，通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。</p><h1 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h1><p>要以读文件的模式打开一个文件对象，使用Python内置的open()函数，传入文件名和标示符：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;/Users/michael/test.txt&apos;, &apos;r&apos;)</span><br></pre></td></tr></table></figure></p><p>标示符’r’表示读，这样，我们就成功地打开了一个文件。</p><p>如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f=open(&apos;/Users/michael/notfound.txt&apos;, &apos;r&apos;)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line">FileNotFoundError: [Errno 2] No such file or directory: &apos;/Users/michael/notfound.txt&apos;</span><br></pre></td></tr></table></figure></p><p>如果文件打开成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读到内存，用一个str对象表示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f.read()</span><br><span class="line">&apos;Hello, world!&apos;</span><br></pre></td></tr></table></figure></p><p>最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f.close()</span><br></pre></td></tr></table></figure></p><p>由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try … finally来实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">try:</span><br><span class="line">    f = open(&apos;/path/to/file&apos;, &apos;r&apos;)</span><br><span class="line">    print(f.read())</span><br><span class="line">finally:</span><br><span class="line">    if f:</span><br><span class="line">        f.close()</span><br></pre></td></tr></table></figure></p><p>但是每次都这么写实在太繁琐，所以，Python引入了with语句来自动帮我们调用close()方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">with open(&apos;/path/to/file&apos;, &apos;r&apos;) as f:</span><br><span class="line">    print(f.read())</span><br></pre></td></tr></table></figure></p><p>这和前面的try … finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。</p><p>调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。</p><p>如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">for line in f.readlines():</span><br><span class="line">    print(line.strip()) # 把末尾的&apos;\n&apos;删掉</span><br></pre></td></tr></table></figure></p><h1 id="file-like-Object"><a href="#file-like-Object" class="headerlink" title="file-like Object"></a>file-like Object</h1><p>像open()函数返回的这种有个read()方法的对象，在Python中统称为file-like Object。除了file外，还可以是内存的字节流，网络流，自定义流等等。file-like Object不要求从特定类继承，只要写个read()方法就行。</p><p>StringIO就是在内存中创建的file-like Object，常用作临时缓冲。</p><h1 id="二进制文件"><a href="#二进制文件" class="headerlink" title="二进制文件"></a>二进制文件</h1><p>前面讲的默认都是读取文本文件，并且是UTF-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用’rb’模式打开文件即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;/Users/michael/test.jpg&apos;, &apos;rb&apos;)</span><br><span class="line">&gt;&gt;&gt; f.read()</span><br><span class="line">b&apos;\xff\xd8\xff\xe1\x00\x18Exif\x00\x00...&apos; # 十六进制表示的字节</span><br></pre></td></tr></table></figure></p><h1 id="字符编码"><a href="#字符编码" class="headerlink" title="字符编码"></a>字符编码</h1><p>要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;/Users/michael/gbk.txt&apos;, &apos;r&apos;, encoding=&apos;gbk&apos;)</span><br><span class="line">&gt;&gt;&gt; f.read()</span><br><span class="line">&apos;测试&apos;</span><br></pre></td></tr></table></figure></p><p>遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;/Users/michael/gbk.txt&apos;, &apos;r&apos;, encoding=&apos;gbk&apos;, errors=&apos;ignore&apos;)</span><br></pre></td></tr></table></figure></p><h1 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h1><p>写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符’w’或者’wb’表示写文本文件或写二进制文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;/Users/michael/test.txt&apos;, &apos;w&apos;)</span><br><span class="line">&gt;&gt;&gt; f.write(&apos;Hello, world!&apos;)</span><br><span class="line">&gt;&gt;&gt; f.close()</span><br></pre></td></tr></table></figure></p><p>你可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">with open(&apos;/Users/michael/test.txt&apos;, &apos;w&apos;) as f:</span><br><span class="line">    f.write(&apos;Hello, world!&apos;)</span><br></pre></td></tr></table></figure></p><p>要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码。</p><p>细心的童鞋会发现，以’w’模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。如果我们希望追加到文件末尾怎么办？可以传入’a’以追加（append）模式写入。</p><p>所有模式的定义及含义可以参考Python的官方文档。</p><h1 id="需要多次读取同一文件内容"><a href="#需要多次读取同一文件内容" class="headerlink" title="需要多次读取同一文件内容"></a>需要多次读取同一文件内容</h1><p>python在读取文件的时候是根据光标位置来读取的。读一行以后光标位置到了下一行。再来个read又到了下一行。</p><p>想要重新从头开始读的话用f.seek(0)</p><p>将光标位置放到最前面。这样再f.read()就是第一行的内容</p><p>还有个方法是f.tell()</p><p>告诉你当前光标的位置。你可以把文件都读完了以后f.tell()一下看看光标位置</p><p>然后再f.seek(0)  </p><p>再f.tell()一下看看光标位置<br>如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; f = f.open(&apos;a.txt&apos;,&apos;r&apos;)</span><br><span class="line">&gt;&gt;&gt; f.read()</span><br><span class="line">&gt;&gt;&gt; &apos;abc&apos;</span><br><span class="line">&gt;&gt;&gt; f.read()</span><br><span class="line">&gt;&gt;&gt; &apos;&apos;</span><br><span class="line">&gt;&gt;&gt; f.seek(0)</span><br><span class="line">&gt;&gt;&gt; &apos;abc&apos;</span><br><span class="line">&gt;&gt;&gt; f.seek(1)</span><br><span class="line">&gt;&gt;&gt; &apos;bc&apos;</span><br></pre></td></tr></table></figure></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在Python中，文件读写是通过open()函数打开的文件对象完成的。使用with语句操作文件IO是个好习惯。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;读写文件是最常见的IO操作。Python内置了读写文件的函数，用法和C是兼容的。&lt;/p&gt;
&lt;p&gt;读写文件前，我们先必须了解一下，在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，所以，读写文件就是请求操作系统打开一个文件对象（通常称为文件
      
    
    </summary>
    
      <category term="python" scheme="https://snjl.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="文件" scheme="https://snjl.github.io/tags/%E6%96%87%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>操作文件和目录</title>
    <link href="https://snjl.github.io/2019/01/31/%E6%93%8D%E4%BD%9C%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"/>
    <id>https://snjl.github.io/2019/01/31/操作文件和目录/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:18:22.418Z</updated>
    
    <content type="html"><![CDATA[<p>如果我们要操作文件、目录，可以在命令行下面输入操作系统提供的各种命令来完成。比如dir、cp等命令。</p><p>如果要在Python程序中执行这些目录和文件的操作怎么办？其实操作系统提供的命令只是简单地调用了操作系统提供的接口函数，Python内置的os模块也可以直接调用操作系统提供的接口函数。</p><p>打开Python交互式命令行，我们来看看如何使用os模块的基本功能：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; import os</span><br><span class="line">&gt;&gt;&gt; os.name # 操作系统类型</span><br><span class="line">&apos;posix&apos;</span><br></pre></td></tr></table></figure></p><p>如果是posix，说明系统是Linux、Unix或Mac OS X，如果是nt，就是Windows系统。</p><p>要获取详细的系统信息，可以调用uname()函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; os.uname()</span><br><span class="line">posix.uname_result(sysname=&apos;Darwin&apos;, nodename=&apos;MichaelMacPro.local&apos;, release=&apos;14.3.0&apos;, version=&apos;Darwin Kernel Version 14.3.0: Mon Mar 23 11:59:05 PDT 2015; root:xnu-2782.20.48~5/RELEASE_X86_64&apos;, machine=&apos;x86_64&apos;)</span><br></pre></td></tr></table></figure></p><p>注意uname()函数在Windows上不提供，也就是说，os模块的某些函数是跟操作系统相关的。</p><h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><p>在操作系统中定义的环境变量，全部保存在os.environ这个变量中，可以直接查看：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; os.environ</span><br><span class="line">environ(&#123;&apos;VERSIONER_PYTHON_PREFER_32_BIT&apos;: &apos;no&apos;, &apos;TERM_PROGRAM_VERSION&apos;: &apos;326&apos;, &apos;LOGNAME&apos;: &apos;michael&apos;, &apos;USER&apos;: &apos;michael&apos;, &apos;PATH&apos;: &apos;/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/mysql/bin&apos;, ...&#125;)</span><br></pre></td></tr></table></figure></p><p>要获取某个环境变量的值，可以调用os.environ.get(‘key’)：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; os.environ.get(&apos;PATH&apos;)</span><br><span class="line">&apos;/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/mysql/bin&apos;</span><br><span class="line">&gt;&gt;&gt; os.environ.get(&apos;x&apos;, &apos;default&apos;)</span><br><span class="line">&apos;default&apos;</span><br></pre></td></tr></table></figure></p><h1 id="操作文件和目录"><a href="#操作文件和目录" class="headerlink" title="操作文件和目录"></a>操作文件和目录</h1><p>操作文件和目录的函数一部分放在os模块中，一部分放在os.path模块中，这一点要注意一下。查看、创建和删除目录可以这么调用：</p><h1 id="查看当前目录的绝对路径"><a href="#查看当前目录的绝对路径" class="headerlink" title="查看当前目录的绝对路径:"></a>查看当前目录的绝对路径:</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; os.path.abspath(&apos;.&apos;)</span><br><span class="line">&apos;/Users/michael&apos;</span><br><span class="line"># 在某个目录下创建一个新目录，首先把新目录的完整路径表示出来:</span><br><span class="line">&gt;&gt;&gt; os.path.join(&apos;/Users/michael&apos;, &apos;testdir&apos;)</span><br><span class="line">&apos;/Users/michael/testdir&apos;</span><br><span class="line"># 然后创建一个目录:</span><br><span class="line">&gt;&gt;&gt; os.mkdir(&apos;/Users/michael/testdir&apos;)</span><br><span class="line"># 删掉一个目录:</span><br><span class="line">&gt;&gt;&gt; os.rmdir(&apos;/Users/michael/testdir&apos;)</span><br></pre></td></tr></table></figure><p>把两个路径合成一个时，不要直接拼字符串，而要通过os.path.join()函数，这样可以正确处理不同操作系统的路径分隔符。在Linux/Unix/Mac下，os.path.join()返回这样的字符串：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">part-1/part-2</span><br></pre></td></tr></table></figure></p><p>而Windows下会返回这样的字符串：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">part-1\part-2</span><br></pre></td></tr></table></figure></p><p>同样的道理，要拆分路径时，也不要直接去拆字符串，而要通过os.path.split()函数，这样可以把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; os.path.split(&apos;/Users/michael/testdir/file.txt&apos;)</span><br><span class="line">(&apos;/Users/michael/testdir&apos;, &apos;file.txt&apos;)</span><br><span class="line">os.path.splitext()可以直接让你得到文件扩展名，很多时候非常方便：</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; os.path.splitext(&apos;/path/to/file.txt&apos;)</span><br><span class="line">(&apos;/path/to/file&apos;, &apos;.txt&apos;)</span><br></pre></td></tr></table></figure></p><p>这些合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作。</p><p>文件操作使用下面的函数。假定当前目录下有一个test.txt文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 对文件重命名:</span><br><span class="line">&gt;&gt;&gt; os.rename(&apos;test.txt&apos;, &apos;test.py&apos;)</span><br><span class="line"># 删掉文件:</span><br><span class="line">&gt;&gt;&gt; os.remove(&apos;test.py&apos;)</span><br></pre></td></tr></table></figure></p><p>但是复制文件的函数居然在os模块中不存在！原因是复制文件并非由操作系统提供的系统调用。理论上讲，我们通过上一节的读写文件可以完成文件复制，只不过要多写很多代码。</p><p>幸运的是shutil模块提供了copyfile()的函数，你还可以在shutil模块中找到很多实用函数，它们可以看做是os模块的补充。</p><p>最后看看如何利用Python的特性来过滤文件。比如我们要列出当前目录下的所有目录，只需要一行代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; [x for x in os.listdir(&apos;.&apos;) if os.path.isdir(x)]</span><br><span class="line">[&apos;.lein&apos;, &apos;.local&apos;, &apos;.m2&apos;, &apos;.npm&apos;, &apos;.ssh&apos;, &apos;.Trash&apos;, &apos;.vim&apos;, &apos;Applications&apos;, &apos;Desktop&apos;, ...]</span><br></pre></td></tr></table></figure></p><p>要列出所有的.py文件，也只需一行代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; [x for x in os.listdir(&apos;.&apos;) if os.path.isfile(x) and os.path.splitext(x)[1]==&apos;.py&apos;]</span><br><span class="line">[&apos;apis.py&apos;, &apos;config.py&apos;, &apos;models.py&apos;, &apos;pymonitor.py&apos;, &apos;test_db.py&apos;, &apos;urls.py&apos;, &apos;wsgiapp.py&apos;]</span><br></pre></td></tr></table></figure></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Python的os模块封装了操作系统的目录和文件操作，要注意这些函数有的在os模块中，有的在os.path模块中。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果我们要操作文件、目录，可以在命令行下面输入操作系统提供的各种命令来完成。比如dir、cp等命令。&lt;/p&gt;
&lt;p&gt;如果要在Python程序中执行这些目录和文件的操作怎么办？其实操作系统提供的命令只是简单地调用了操作系统提供的接口函数，Python内置的os模块也可以直接调
      
    
    </summary>
    
      <category term="python" scheme="https://snjl.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="文件" scheme="https://snjl.github.io/tags/%E6%96%87%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu18.04安装Mysql时未让输入密码</title>
    <link href="https://snjl.github.io/2019/01/31/Ubuntu18.04%20%E5%AE%89%E8%A3%85Mysql%E6%97%B6%E6%9C%AA%E8%AE%A9%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81/"/>
    <id>https://snjl.github.io/2019/01/31/Ubuntu18.04 安装Mysql时未让输入密码/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:15:55.495Z</updated>
    
    <content type="html"><![CDATA[<p>在ubuntu18.04中使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install mysql-server</span><br></pre></td></tr></table></figure></p><p>安装数据库时，在安装过程中，并没有像ubuntu16中提示输入root用户的密码，所以无法登录。</p><h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>mysql5.7暂时不支持ubuntu18.04，所以需要安装mysql8.0，需要引入mysql的deb。</p><h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1><p>下载 <a href="https://dev.mysql.com/downloads/repo/apt/" target="_blank" rel="noopener">https://dev.mysql.com/downloads/repo/apt/</a> 中的deb包。<br>使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -i deb_name</span><br></pre></td></tr></table></figure></p><p>根据需求选择配置。</p><p>然后<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt update </span><br><span class="line">apt install mysql-server</span><br></pre></td></tr></table></figure></p><p>此时的安装过程就会提示输入root密码，安装完成后普通用户也能直接登录。</p><p><strong>注：mysql8.0很多配置方面与mysql5.7不一样，所以可能需要先使用ubuntu16.04安装好mysql后更新到18.04，或者不更新，或者等mysql5.7支持18.04版本后再安装。或者使用docker。。。 </strong></p><h1 id="mysql8-0使用原先配置产生的问题（已发现）"><a href="#mysql8-0使用原先配置产生的问题（已发现）" class="headerlink" title="mysql8.0使用原先配置产生的问题（已发现）"></a>mysql8.0使用原先配置产生的问题（已发现）</h1><p>设置mysqld的sql_mode的时候会出现bug，无法设置。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在ubuntu18.04中使用&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class
      
    
    </summary>
    
      <category term="服务器" scheme="https://snjl.github.io/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
    
      <category term="ubuntu" scheme="https://snjl.github.io/tags/ubuntu/"/>
    
      <category term="mysql" scheme="https://snjl.github.io/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>winscp服务器拒绝了SFTP连接，但它监听FTP连接</title>
    <link href="https://snjl.github.io/2019/01/31/winscp%20%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8B%92%E7%BB%9D%E4%BA%86SFTP%E8%BF%9E%E6%8E%A5%EF%BC%8C%E4%BD%86%E5%AE%83%E7%9B%91%E5%90%ACFTP%E8%BF%9E%E6%8E%A5/"/>
    <id>https://snjl.github.io/2019/01/31/winscp 服务器拒绝了SFTP连接，但它监听FTP连接/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:16:59.822Z</updated>
    
    <content type="html"><![CDATA[<p>出错：  在linux系统上没有安装sshd或者sshd配置出错</p><p>原因是没有安装sshd或者sshd配置出错。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>安装openssh-server<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install openssh-server</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;出错：  在linux系统上没有安装sshd或者sshd配置出错&lt;/p&gt;
&lt;p&gt;原因是没有安装sshd或者sshd配置出错。&lt;/p&gt;
&lt;h1 id=&quot;解决方法&quot;&gt;&lt;a href=&quot;#解决方法&quot; class=&quot;headerlink&quot; title=&quot;解决方法&quot;&gt;&lt;/a&gt;解决方法
      
    
    </summary>
    
      <category term="报错" scheme="https://snjl.github.io/categories/%E6%8A%A5%E9%94%99/"/>
    
      <category term="服务器" scheme="https://snjl.github.io/categories/%E6%8A%A5%E9%94%99/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
    
      <category term="服务器" scheme="https://snjl.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
      <category term="报错" scheme="https://snjl.github.io/tags/%E6%8A%A5%E9%94%99/"/>
    
  </entry>
  
  <entry>
    <title>python IO编程</title>
    <link href="https://snjl.github.io/2019/01/31/python%20IO%E7%BC%96%E7%A8%8B/"/>
    <id>https://snjl.github.io/2019/01/31/python IO编程/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T06:28:10.540Z</updated>
    
    <content type="html"><![CDATA[<p>IO在计算机中指Input/Output，也就是输入和输出。由于程序和运行时数据是在内存中驻留，由CPU这个超快的计算核心来执行，涉及到数据交换的地方，通常是磁盘、网络等，就需要IO接口。</p><p>比如你打开浏览器，访问新浪首页，浏览器这个程序就需要通过网络IO获取新浪的网页。浏览器首先会发送数据给新浪服务器，告诉它我想要首页的HTML，这个动作是往外发数据，叫Output，随后新浪服务器把网页发过来，这个动作是从外面接收数据，叫Input。所以，通常，程序完成IO操作会有Input和Output两个数据流。当然也有只用一个的情况，比如，从磁盘读取文件到内存，就只有Input操作，反过来，把数据写到磁盘文件里，就只是一个Output操作。</p><p>IO编程中，Stream（流）是一个很重要的概念，可以把流想象成一个水管，数据就是水管里的水，但是只能单向流动。Input Stream就是数据从外面（磁盘、网络）流进内存，Output Stream就是数据从内存流到外面去。对于浏览网页来说，浏览器和新浪服务器之间至少需要建立两根水管，才可以既能发数据，又能收数据。</p><p>由于CPU和内存的速度远远高于外设的速度，所以，在IO编程中，就存在速度严重不匹配的问题。举个例子来说，比如要把100M的数据写入磁盘，CPU输出100M的数据只需要0.01秒，可是磁盘要接收这100M数据可能需要10秒，怎么办呢？有两种办法：</p><p>第一种是CPU等着，也就是程序暂停执行后续代码，等100M的数据在10秒后写入磁盘，再接着往下执行，这种模式称为同步IO；</p><p>另一种方法是CPU不等待，只是告诉磁盘，“您老慢慢写，不着急，我接着干别的事去了”，于是，后续代码可以立刻接着执行，这种模式称为异步IO。</p><p>同步和异步的区别就在于是否等待IO执行的结果。好比你去麦当劳点餐，你说“来个汉堡”，服务员告诉你，对不起，汉堡要现做，需要等5分钟，于是你站在收银台前面等了5分钟，拿到汉堡再去逛商场，这是同步IO。</p><p>你说“来个汉堡”，服务员告诉你，汉堡需要等5分钟，你可以先去逛商场，等做好了，我们再通知你，这样你可以立刻去干别的事情（逛商场），这是异步IO。</p><p>很明显，使用异步IO来编写程序性能会远远高于同步IO，但是异步IO的缺点是编程模型复杂。想想看，你得知道什么时候通知你“汉堡做好了”，而通知你的方法也各不相同。如果是服务员跑过来找到你，这是回调模式，如果服务员发短信通知你，你就得不停地检查手机，这是轮询模式。总之，异步IO的复杂度远远高于同步IO。</p><p>操作IO的能力都是由操作系统提供的，每一种编程语言都会把操作系统提供的低级C接口封装起来方便使用，Python也不例外。我们后面会详细讨论Python的IO编程接口。</p><p>注意，本章的IO编程都是同步模式，异步IO由于复杂度太高，后续涉及到服务器端程序开发时我们再讨论。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;IO在计算机中指Input/Output，也就是输入和输出。由于程序和运行时数据是在内存中驻留，由CPU这个超快的计算核心来执行，涉及到数据交换的地方，通常是磁盘、网络等，就需要IO接口。&lt;/p&gt;
&lt;p&gt;比如你打开浏览器，访问新浪首页，浏览器这个程序就需要通过网络IO获取新
      
    
    </summary>
    
      <category term="python" scheme="https://snjl.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="IO" scheme="https://snjl.github.io/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>序列化</title>
    <link href="https://snjl.github.io/2019/01/31/%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>https://snjl.github.io/2019/01/31/序列化/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:13:20.940Z</updated>
    
    <content type="html"><![CDATA[<p>在程序运行的过程中，所有的变量都是在内存中，比如，定义一个dict：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = dict(name=&apos;Bob&apos;, age=20, score=88)</span><br></pre></td></tr></table></figure></p><p>可以随时修改变量，比如把name改成’Bill’，但是一旦程序结束，变量所占用的内存就被操作系统全部回收。如果没有把修改后的’Bill’存储到磁盘上，下次重新运行程序，变量又被初始化为’Bob’。</p><p>我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等，都是一个意思。</p><p>序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。</p><p>反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。</p><p>Python提供了pickle模块来实现序列化。</p><p>首先，我们尝试把一个对象序列化并写入文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import pickle</span><br><span class="line">&gt;&gt;&gt; d = dict(name=&apos;Bob&apos;, age=20, score=88)</span><br><span class="line">&gt;&gt;&gt; pickle.dumps(d)</span><br><span class="line">b&apos;\x80\x03&#125;q\x00(X\x03\x00\x00\x00ageq\x01K\x14X\x05\x00\x00\x00scoreq\x02KXX\x04\x00\x00\x00nameq\x03X\x03\x00\x00\x00Bobq\x04u.&apos;</span><br></pre></td></tr></table></figure></p><p>pickle.dumps()方法把任意对象序列化成一个bytes，然后，就可以把这个bytes写入文件。或者用另一个方法pickle.dump()直接把对象序列化后写入一个file-like Object：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; f = open(&apos;dump.txt&apos;, &apos;wb&apos;)</span><br><span class="line">&gt;&gt;&gt; pickle.dump(d, f)</span><br><span class="line">&gt;&gt;&gt; f.close()</span><br></pre></td></tr></table></figure></p><p>看看写入的dump.txt文件，一堆乱七八糟的内容，这些都是Python保存的对象内部信息。</p><p>当我们要把对象从磁盘读到内存时，可以先把内容读到一个bytes，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个file-like Object中直接反序列化出对象。我们打开另一个Python命令行来反序列化刚才保存的对象：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; f = open(&apos;dump.txt&apos;, &apos;rb&apos;)</span><br><span class="line">&gt;&gt;&gt; d = pickle.load(f)</span><br><span class="line">&gt;&gt;&gt; f.close()</span><br><span class="line">&gt;&gt;&gt; d</span><br><span class="line">&#123;&apos;age&apos;: 20, &apos;score&apos;: 88, &apos;name&apos;: &apos;Bob&apos;&#125;</span><br></pre></td></tr></table></figure></p><p>变量的内容又回来了！</p><p>当然，这个变量和原来的变量是完全不相干的对象，它们只是内容相同而已。</p><p>Pickle的问题和所有其他编程语言特有的序列化问题一样，就是它只能用于Python，并且可能不同版本的Python彼此都不兼容，因此，只能用Pickle保存那些不重要的数据，不能成功地反序列化也没关系。</p><h1 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h1><p>如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便。</p><p>JSON表示的对象就是标准的JavaScript语言的对象，JSON和Python内置的数据类型对应如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">JSON类型Python类型</span><br><span class="line">&#123;&#125;dict</span><br><span class="line">[]list</span><br><span class="line">&quot;string&quot;str</span><br><span class="line">1234.56int或float</span><br><span class="line">true/falseTrue/False</span><br><span class="line">nullNone</span><br></pre></td></tr></table></figure></p><p>Python内置的json模块提供了非常完善的Python对象到JSON格式的转换。我们先看看如何把Python对象变成一个JSON：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import json</span><br><span class="line">&gt;&gt;&gt; d = dict(name=&apos;Bob&apos;, age=20, score=88)</span><br><span class="line">&gt;&gt;&gt; json.dumps(d)</span><br><span class="line">&apos;&#123;&quot;age&quot;: 20, &quot;score&quot;: 88, &quot;name&quot;: &quot;Bob&quot;&#125;&apos;</span><br></pre></td></tr></table></figure></p><p>dumps()方法返回一个str，内容就是标准的JSON。类似的，dump()方法可以直接把JSON写入一个file-like Object。</p><p>要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; f = open(&apos;d.txt&apos;,&apos;w&apos;) #此处是w写入，不是wb，写入的文件可读</span><br><span class="line">&gt;&gt;&gt; json.dump(d,f) # 将d写入文件f中</span><br><span class="line">&gt;&gt;&gt; f.close()</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;d.txt&apos;,&apos;r&apos;) # 从文件读入json的方式一</span><br><span class="line">&gt;&gt;&gt; w = json.load(f)</span><br><span class="line">&gt;&gt;&gt; w</span><br><span class="line">&apos;&#123;&quot;age&quot;: 20, &quot;score&quot;: 88, &quot;name&quot;: &quot;Bob&quot;&#125;&apos;</span><br><span class="line">&gt;&gt;&gt; f.close()</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; f = open(&apos;d.txt&apos;,&apos;r&apos;) # 从文件读入json的方式二</span><br><span class="line">&gt;&gt;&gt; w = json.loads(f.read())</span><br><span class="line">&gt;&gt;&gt; w</span><br><span class="line">&apos;&#123;&quot;age&quot;: 20, &quot;score&quot;: 88, &quot;name&quot;: &quot;Bob&quot;&#125;&apos;</span><br><span class="line">&gt;&gt;&gt; f.close()</span><br></pre></td></tr></table></figure></p><p><strong>注意：使用dump方法写入文件时，文件打开方式要为w，而不是wb。如果将文件读成字符串，使用的是load，如果直接读入文件，使用的是loads。</strong><br>由于JSON标准规定JSON编码是UTF-8，所以我们总是能正确地在Python的str与JSON的字符串之间转换。</p><h1 id="JSON进阶"><a href="#JSON进阶" class="headerlink" title="JSON进阶"></a>JSON进阶</h1><p>Python的dict对象可以直接序列化为JSON的{}，不过，很多时候，我们更喜欢用class表示对象，比如定义Student类，然后序列化：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line"></span><br><span class="line">class Student(object):</span><br><span class="line">    def __init__(self, name, age, score):</span><br><span class="line">        self.name = name</span><br><span class="line">        self.age = age</span><br><span class="line">        self.score = score</span><br><span class="line"></span><br><span class="line">s = Student(&apos;Bob&apos;, 20, 88)</span><br><span class="line">print(json.dumps(s))</span><br></pre></td></tr></table></figure></p><p>运行代码，毫不留情地得到一个TypeError：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  ...</span><br><span class="line">TypeError: &lt;__main__.Student object at 0x10603cc50&gt; is not JSON serializable</span><br></pre></td></tr></table></figure></p><p>错误的原因是Student对象不是一个可序列化为JSON的对象。</p><p>如果连class的实例对象都无法序列化为JSON，这肯定不合理！</p><p>别急，我们仔细看看dumps()方法的参数列表，可以发现，除了第一个必须的obj参数外，dumps()方法还提供了一大堆的可选参数：</p><p><a href="https://docs.python.org/3/library/json.html#json.dumps" target="_blank" rel="noopener">https://docs.python.org/3/library/json.html#json.dumps</a></p><p>这些可选参数就是让我们来定制JSON序列化。前面的代码之所以无法把Student类实例序列化为JSON，是因为默认情况下，dumps()方法不知道如何将Student实例变为一个JSON的{}对象。</p><p>可选参数default就是把任意一个对象变成一个可序列为JSON的对象，我们只需要为Student专门写一个转换函数，再把函数传进去即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def student2dict(std):</span><br><span class="line">    return &#123;</span><br><span class="line">        &apos;name&apos;: std.name,</span><br><span class="line">        &apos;age&apos;: std.age,</span><br><span class="line">        &apos;score&apos;: std.score</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>这样，Student实例首先被student2dict()函数转换成dict，然后再被顺利序列化为JSON：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print(json.dumps(s, default=student2dict))</span><br><span class="line">&#123;&quot;age&quot;: 20, &quot;name&quot;: &quot;Bob&quot;, &quot;score&quot;: 88&#125;</span><br></pre></td></tr></table></figure></p><p>不过，下次如果遇到一个Teacher类的实例，照样无法序列化为JSON。我们可以偷个懒，把任意class的实例变为dict：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(json.dumps(s, default=lambda obj: obj.__dict__))</span><br></pre></td></tr></table></figure></p><p>因为通常class的实例都有一个<strong>dict</strong>属性，它就是一个dict，用来存储实例变量。也有少数例外，比如定义了<strong>slots</strong>的class。</p><p>同样的道理，如果我们要把JSON反序列化为一个Student对象实例，loads()方法首先转换出一个dict对象，然后，我们传入的object_hook函数负责把dict转换为Student实例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def dict2student(d):</span><br><span class="line">    return Student(d[&apos;name&apos;], d[&apos;age&apos;], d[&apos;score&apos;])</span><br></pre></td></tr></table></figure></p><p>运行结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; json_str = &apos;&#123;&quot;age&quot;: 20, &quot;score&quot;: 88, &quot;name&quot;: &quot;Bob&quot;&#125;&apos;</span><br><span class="line">&gt;&gt;&gt; print(json.loads(json_str, object_hook=dict2student))</span><br><span class="line">&lt;__main__.Student object at 0x10cd3c190&gt;</span><br></pre></td></tr></table></figure></p><p>打印出的是反序列化的Student实例对象。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>Python语言特定的序列化模块是pickle，但如果要把序列化搞得更通用、更符合Web标准，就可以使用json模块。</p><p>json模块的dumps()和loads()函数是定义得非常好的接口的典范。当我们使用时，只需要传入一个必须的参数。但是，当默认的序列化或反序列机制不满足我们的要求时，我们又可以传入更多的参数来定制序列化或反序列化的规则，既做到了接口简单易用，又做到了充分的扩展性和灵活性。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在程序运行的过程中，所有的变量都是在内存中，比如，定义一个dict：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;
      
    
    </summary>
    
      <category term="python" scheme="https://snjl.github.io/categories/python/"/>
    
    
      <category term="序列化" scheme="https://snjl.github.io/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    
      <category term="json" scheme="https://snjl.github.io/tags/json/"/>
    
  </entry>
  
  <entry>
    <title>无界面selenium</title>
    <link href="https://snjl.github.io/2019/01/31/%E6%97%A0%E7%95%8C%E9%9D%A2selenium/"/>
    <id>https://snjl.github.io/2019/01/31/无界面selenium/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:20:16.146Z</updated>
    
    <content type="html"><![CDATA[<p>selenium中文文档：<a href="https://selenium-python-zh.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">https://selenium-python-zh.readthedocs.io/en/latest/index.html</a></p><p>使用selenium，安装好对应版本的chromedriver和chrome，然后将driver放入项目，用 driver = webdriver.Chrome()启动。</p><p>selenium刷新：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">driver.refresh()</span><br><span class="line"><span class="comment"># 或调用js</span></span><br><span class="line">driver.execute_script(<span class="string">"location.reload()"</span>)</span><br></pre></td></tr></table></figure></p><p>请求头配置参考：<a href="https://blog.csdn.net/u013440574/article/details/81911954" target="_blank" rel="noopener">https://blog.csdn.net/u013440574/article/details/81911954</a></p><p>仅添加普通请求头：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">opt = webdriver.ChromeOptions()</span><br><span class="line">   opt.set_headless()</span><br><span class="line">   opt.add_argument(</span><br><span class="line">       <span class="string">'user-agent=Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.26 Safari/537.36 Core/1.63.6726.400 QQBrowser/10.2.2265.400'</span>)</span><br><span class="line"></span><br><span class="line">   driver = webdriver.Chrome(options=opt)</span><br></pre></td></tr></table></figure></p><p>这里使用opt作为chromedriver的参数，添加user-agent信息，然后调用webdriver.Chrome，并传入opt。</p><p><strong>注：这里使用的是无窗口界面的chrome selenium爬虫，所以可以设置，如果使用有界面的，则不必设置，因为带界面必定带请求头和各种信息。</strong></p><p>Selenium不再推荐使用PhantomJS，会报如下警告<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead</span><br><span class="line"> warnings.warn(&apos;Selenium support for PhantomJS has been deprecated, please use headless &apos;</span><br></pre></td></tr></table></figure></p><p>于是从PhantomJS转移到Chrome，使用headless versions of Chrome时，首先要安装Chrome，然后下载chromedriver，再把chromedriver的地址配置到系统环境变量path中，方便调用。如果不把chromedriver的地址配置到系统环境变量的话，也可以在使用时指定chromedriver的地址。</p><p>注意Chrome和chromedriver有版本对应的要求，系统中安装了某一版本的chrome要使用对应版本的chromedriver，其实下载最新版本的Chrome和chromedriver就行了，一般都是对应的。</p><p>Chrome下载地址：<a href="https://chrome.en.softonic.com/" target="_blank" rel="noopener">https://chrome.en.softonic.com/</a></p><p>chromedriver下载地址：<a href="http://npm.taobao.org/mirrors/chromedriver/" target="_blank" rel="noopener">http://npm.taobao.org/mirrors/chromedriver/</a></p><h1 id="报错：-0917-002914-533-ERROR-gpu-process-transport-factory-cc-1007-Lost-UI-shared-context"><a href="#报错：-0917-002914-533-ERROR-gpu-process-transport-factory-cc-1007-Lost-UI-shared-context" class="headerlink" title="报错：[0917/002914.533:ERROR:gpu_process_transport_factory.cc(1007)] Lost UI shared context."></a>报错：[0917/002914.533:ERROR:gpu_process_transport_factory.cc(1007)] Lost UI shared context.</h1><p>原因是在windows系统中Chrome无头模式下，其中的SwiftShader软件会触发断言失败，但实际上不影响程序执行，可以忽略该错误。</p><p>可以设置chromedriver的日志级别，只有大于设置级别的日志还会输出，该配置参数为：log-level：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">opt.add_argument(<span class="string">'log-level=3'</span>)</span><br><span class="line"><span class="comment"># INFO = 0, </span></span><br><span class="line"><span class="comment"># WARNING = 1, </span></span><br><span class="line"><span class="comment"># LOG_ERROR = 2, </span></span><br><span class="line"><span class="comment"># LOG_FATAL = 3</span></span><br><span class="line"><span class="comment"># default is 0</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;selenium中文文档：&lt;a href=&quot;https://selenium-python-zh.readthedocs.io/en/latest/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://selenium-pyt
      
    
    </summary>
    
      <category term="爬虫" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="爬虫" scheme="https://snjl.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="selenium" scheme="https://snjl.github.io/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>文档测试</title>
    <link href="https://snjl.github.io/2019/01/31/%E6%96%87%E6%A1%A3%E6%B5%8B%E8%AF%95/"/>
    <id>https://snjl.github.io/2019/01/31/文档测试/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T07:18:47.571Z</updated>
    
    <content type="html"><![CDATA[<p>如果你经常阅读Python的官方文档，可以看到很多文档都有示例代码。比如re模块就带了很多示例代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; import re</span><br><span class="line">&gt;&gt;&gt; m = re.search(&apos;(?&lt;=abc)def&apos;, &apos;abcdef&apos;)</span><br><span class="line">&gt;&gt;&gt; m.group(0)</span><br><span class="line">&apos;def&apos;</span><br></pre></td></tr></table></figure></p><p>可以把这些示例代码在Python的交互式环境下输入并执行，结果与文档中的示例代码显示的一致。</p><p>这些代码与其他说明可以写在注释中，然后，由一些工具来自动生成文档。既然这些代码本身就可以粘贴出来直接运行，那么，可不可以自动执行写在注释中的这些代码呢？</p><p>答案是肯定的。</p><p>当我们编写注释时，如果写上这样的注释：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def abs(n):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Function to get absolute value of number.</span><br><span class="line"></span><br><span class="line">    Example:</span><br><span class="line"></span><br><span class="line">    &gt;&gt;&gt; abs(1)</span><br><span class="line">    1</span><br><span class="line">    &gt;&gt;&gt; abs(-1)</span><br><span class="line">    1</span><br><span class="line">    &gt;&gt;&gt; abs(0)</span><br><span class="line">    0</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    return n if n &gt;= 0 else (-n)</span><br></pre></td></tr></table></figure></p><p>无疑更明确地告诉函数的调用者该函数的期望输入和输出。</p><p>并且，Python内置的“文档测试”（doctest）模块可以直接提取注释中的代码并执行测试。</p><p>doctest严格按照Python交互式命令行的输入和输出来判断测试结果是否正确。只有测试异常的时候，可以用…表示中间一大段烦人的输出。</p><p>让我们用doctest来测试上次编写的Dict类：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># mydict2.py</span><br><span class="line">class Dict(dict):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    Simple dict but also support access as x.y style.</span><br><span class="line"></span><br><span class="line">    &gt;&gt;&gt; d1 = Dict()</span><br><span class="line">    &gt;&gt;&gt; d1[&apos;x&apos;] = 100</span><br><span class="line">    &gt;&gt;&gt; d1.x</span><br><span class="line">    100</span><br><span class="line">    &gt;&gt;&gt; d1.y = 200</span><br><span class="line">    &gt;&gt;&gt; d1[&apos;y&apos;]</span><br><span class="line">    200</span><br><span class="line">    &gt;&gt;&gt; d2 = Dict(a=1, b=2, c=&apos;3&apos;)</span><br><span class="line">    &gt;&gt;&gt; d2.c</span><br><span class="line">    &apos;3&apos;</span><br><span class="line">    &gt;&gt;&gt; d2[&apos;empty&apos;]</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">        ...</span><br><span class="line">    KeyError: &apos;empty&apos;</span><br><span class="line">    &gt;&gt;&gt; d2.empty</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">        ...</span><br><span class="line">    AttributeError: &apos;Dict&apos; object has no attribute &apos;empty&apos;</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    def __init__(self, **kw):</span><br><span class="line">        super(Dict, self).__init__(**kw)</span><br><span class="line"></span><br><span class="line">    def __getattr__(self, key):</span><br><span class="line">        try:</span><br><span class="line">            return self[key]</span><br><span class="line">        except KeyError:</span><br><span class="line">            raise AttributeError(r&quot;&apos;Dict&apos; object has no attribute &apos;%s&apos;&quot; % key)</span><br><span class="line"></span><br><span class="line">    def __setattr__(self, key, value):</span><br><span class="line">        self[key] = value</span><br><span class="line"></span><br><span class="line">if __name__==&apos;__main__&apos;:</span><br><span class="line">    import doctest</span><br><span class="line">    doctest.testmod()</span><br></pre></td></tr></table></figure></p><p>运行python mydict2.py：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ python mydict2.py</span><br></pre></td></tr></table></figure></p><p>什么输出也没有。这说明我们编写的doctest运行都是正确的。如果程序有问题，比如把<strong>getattr</strong>()方法注释掉，再运行就会报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ python mydict2.py</span><br><span class="line">**********************************************************************</span><br><span class="line">File &quot;/Users/michael/Github/learn-python3/samples/debug/mydict2.py&quot;, line 10, in __main__.Dict</span><br><span class="line">Failed example:</span><br><span class="line">    d1.x</span><br><span class="line">Exception raised:</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">      ...</span><br><span class="line">    AttributeError: &apos;Dict&apos; object has no attribute &apos;x&apos;</span><br><span class="line">**********************************************************************</span><br><span class="line">File &quot;/Users/michael/Github/learn-python3/samples/debug/mydict2.py&quot;, line 16, in __main__.Dict</span><br><span class="line">Failed example:</span><br><span class="line">    d2.c</span><br><span class="line">Exception raised:</span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">      ...</span><br><span class="line">    AttributeError: &apos;Dict&apos; object has no attribute &apos;c&apos;</span><br><span class="line">**********************************************************************</span><br><span class="line">1 items had failures:</span><br><span class="line">   2 of   9 in __main__.Dict</span><br><span class="line">***Test Failed*** 2 failures.</span><br></pre></td></tr></table></figure></p><p>注意到最后3行代码。当模块正常导入时，doctest不会被执行。只有在命令行直接运行时，才执行doctest。所以，不必担心doctest会在非测试环境下执行。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>doctest非常有用，不但可以用来测试，还可以直接作为示例代码。通过某些文档生成工具，就可以自动把包含doctest的注释提取出来。用户看文档的时候，同时也看到了doctest。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;如果你经常阅读Python的官方文档，可以看到很多文档都有示例代码。比如re模块就带了很多示例代码：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;lin
      
    
    </summary>
    
      <category term="python" scheme="https://snjl.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="测试" scheme="https://snjl.github.io/tags/%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>selenium简单使用</title>
    <link href="https://snjl.github.io/2019/01/31/selenium%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"/>
    <id>https://snjl.github.io/2019/01/31/selenium简单使用/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T06:33:01.268Z</updated>
    
    <content type="html"><![CDATA[<p>selenium可以解决js渲染问题，模拟网页加载。</p><h1 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line">from selenium.webdriver.common.keys import Keys</span><br><span class="line">from selenium.webdriver.support import expected_conditions as EC</span><br><span class="line">from selenium.webdriver.support.wait import WebDriverWait</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">try:</span><br><span class="line">    browser.get(&apos;https://www.baidu.com&apos;)</span><br><span class="line">    input = browser.find_element_by_id(&apos;kw&apos;)</span><br><span class="line">    input.send_keys(&apos;Python&apos;)</span><br><span class="line">    input.send_keys(Keys.ENTER)</span><br><span class="line">    wait = WebDriverWait(browser, 10)</span><br><span class="line">    wait.until(EC.presence_of_element_located((By.ID, &apos;content_left&apos;)))</span><br><span class="line">    print(browser.current_url)</span><br><span class="line">    print(browser.get_cookies())</span><br><span class="line">    print(browser.page_source)</span><br><span class="line">finally:</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure><p>运行代码之后，如果正确配置好了ChromeDriver，可以发现会自动弹出一个浏览器，浏览器首先会跳转到百度，然后在搜索框中输入Python进行搜索，然后跳转到搜索结果页，等待搜索结果加载出来之后，控制台分别会输出当前的URL，当前的Cookies还有网页源代码。<br><a id="more"></a><br>控制台输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=0&amp;rsv_idx=1&amp;tn=baidu&amp;wd=Python&amp;rsv_pq=c94d0df9000a72d0&amp;rsv_t=07099xvun1ZmC0bf6eQvygJ43IUTTUOl5FCJVPgwG2YREs70GplJjH2F%2BCQ&amp;rqlang=cn&amp;rsv_enter=1&amp;rsv_sug3=6&amp;rsv_sug2=0&amp;inputT=87&amp;rsv_sug4=87</span><br><span class="line">[&#123;&apos;secure&apos;: False, &apos;value&apos;: &apos;B490B5EBF6F3CD402E515D22BCDA1598&apos;, &apos;domain&apos;: &apos;.baidu.com&apos;, &apos;path&apos;: &apos;/&apos;, &apos;httpOnly&apos;: False, &apos;name&apos;: &apos;BDORZ&apos;, &apos;expiry&apos;: 1491688071.707553&#125;, &#123;&apos;secure&apos;: False, &apos;value&apos;: &apos;22473_1441_21084_17001&apos;, &apos;domain&apos;: &apos;.baidu.com&apos;, &apos;path&apos;: &apos;/&apos;, &apos;httpOnly&apos;: False, &apos;name&apos;: &apos;H_PS_PSSID&apos;&#125;, &#123;&apos;secure&apos;: False, &apos;value&apos;: &apos;12883875381399993259_00_0_I_R_2_0303_C02F_N_I_I_0&apos;, &apos;domain&apos;: &apos;.www.baidu.com&apos;, &apos;path&apos;: &apos;/&apos;, &apos;httpOnly&apos;: False, &apos;name&apos;: &apos;__bsi&apos;, &apos;expiry&apos;: 1491601676.69722&#125;]</span><br><span class="line">&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;...&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>源代码过长在此省略，那么当前的URL，Cookies，源代码都是浏览器中的真实内容。所以说，如果我们用Selenium来驱动浏览器加载网页的话，我们就可以拿到JavaScrit渲染的结果了。</p><p>下面我们来详细介绍一下Selenium的用法。</p><h1 id="声明浏览器对象"><a href="#声明浏览器对象" class="headerlink" title="声明浏览器对象"></a>声明浏览器对象</h1><p>Selenium支持非常多的浏览器，如Chrome、Firefox、Edge等，还有手机端的浏览器Android、BlackBerry等，另外无界面浏览器PhantomJS也同样支持。</p><p>我们可以用如下的方式初始化：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser = webdriver.Firefox()</span><br><span class="line">browser = webdriver.Edge()</span><br><span class="line">browser = webdriver.PhantomJS()</span><br><span class="line">browser = webdriver.Safari()</span><br></pre></td></tr></table></figure></p><p>这样我们就完成了一个浏览器对象的初始化，接下来我们要做的就是调用browser对象，让其执行各个动作，就可以模拟浏览器操作了。</p><h1 id="访问页面"><a href="#访问页面" class="headerlink" title="访问页面"></a>访问页面</h1><p>我们可以用get()方法来请求一个网页，参数传入链接URL即可，比如在这里我们用get()方法访问淘宝，然后打印出源代码，代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.taobao.com&apos;)</span><br><span class="line">print(browser.page_source)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure></p><h1 id="查找元素"><a href="#查找元素" class="headerlink" title="查找元素"></a>查找元素</h1><h2 id="单个元素"><a href="#单个元素" class="headerlink" title="单个元素"></a>单个元素</h2><p>Selenium可以驱动浏览器完成各种操作，比如填充表单，模拟点击等等，比如我们想要完成向某个输入框输入文字的操作，总得需要知道这个输入框在哪里吧？所以Selenium提供了一系列查找元素的方法，我们可以用这些方法来获取想要的元素，以便于下一步执行一些动作或者提取信息。</p><p>比如我们想要从淘宝页面中提取搜索框这个元素，首先观察它的源代码：</p><p>可以发现它的ID是q，Name也是q，还有许多其他属性，我们获取它的方式就有多种形式了，比如find_element_by_name()是根据Name值获取，ind_element_by_id()是根据ID获取，另外还有根据XPath、CSS Selector等获取。</p><p>我们代码实现一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.taobao.com&apos;)</span><br><span class="line">input_first = browser.find_element_by_id(&apos;q&apos;)</span><br><span class="line">input_second = browser.find_element_by_css_selector(&apos;#q&apos;)</span><br><span class="line">input_third = browser.find_element_by_xpath(&apos;//*[@id=&quot;q&quot;]&apos;)</span><br><span class="line">print(input_first, input_second, input_third)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure></p><p>在这里我们使用了三种方式获取输入框，根据ID，CSS Selector，和XPath获取，它们返回的结果是完全一致的。</p><p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;5e53d9e1c8646e44c14c1c2880d424af&quot;, element=&quot;0.5649563096161541-1&quot;)&gt; </span><br><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;5e53d9e1c8646e44c14c1c2880d424af&quot;, element=&quot;0.5649563096161541-1&quot;)&gt; </span><br><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;5e53d9e1c8646e44c14c1c2880d424af&quot;, element=&quot;0.5649563096161541-1&quot;)&gt;</span><br></pre></td></tr></table></figure></p><p>可以看到三个元素都是WebElement类型，是完全一致的。</p><p>在这里列出所有获取单个元素的方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">find_element_by_id</span><br><span class="line">find_element_by_name</span><br><span class="line">find_element_by_xpath</span><br><span class="line">find_element_by_link_text</span><br><span class="line">find_element_by_partial_link_text</span><br><span class="line">find_element_by_tag_name</span><br><span class="line">find_element_by_class_name</span><br><span class="line">find_element_by_css_selector</span><br></pre></td></tr></table></figure></p><p>另外Selenium还提供了通用的find_element()方法，它需要传入两个参数，一个是查找的方式By，另一个就是值，实际上它就是find_element_by_id()这种方法的通用函数版本，比如find_element_by_id(id)就等价于find_element(By.ID, id)。</p><p>我们用代码实现一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.taobao.com&apos;)</span><br><span class="line">input_first = browser.find_element(By.ID, &apos;q&apos;)</span><br><span class="line">print(input_first)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure></p><p>这样的查找方式实际上功能和上面列举的查找函数完全一致，不过参数更加灵活。</p><h2 id="多个元素"><a href="#多个元素" class="headerlink" title="多个元素"></a>多个元素</h2><p>如果我们查找的目标在网页中只有一个，那么完全可以用find_element()方法，但如果有多个元素，再用find_element()方法查找就只能得到第一个元素了，如果要查找所有满足条件的元素，那就需要用find_elements()这样的方法了，方法名称中element多了一个s。</p><p>比如我们在这里查找淘宝导航条的所有条目就可以这样来写：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.taobao.com&apos;)</span><br><span class="line">lis = browser.find_elements_by_css_selector(&apos;.service-bd li&apos;)</span><br><span class="line">print(lis)</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure></p><p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;c26290835d4457ebf7d96bfab3740d19&quot;, element=&quot;0.09221044033125603-1&quot;)&gt;, &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;c26290835d4457ebf7d96bfab3740d19&quot;, element=&quot;0.09221044033125603-2&quot;)&gt;, &lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;c26290835d4457ebf7d96bfab3740d19&quot;, element=&quot;0.09221044033125603-3&quot;)&gt;...&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;c26290835d4457ebf7d96bfab3740d19&quot;, element=&quot;0.09221044033125603-16&quot;)&gt;]</span><br></pre></td></tr></table></figure></p><p>在此简化了一下输出结果，中间部分省略。</p><p>可以看到得到的内容就变成了list类型，list的每个元素都是WebElement类型。</p><p>也就是说，如果我们用find_element()方法，只能获取匹配的第一个元素，结果是WebElement类型，如果用find_elements()方法，则结果是list类型，listd每个元素是WebElement类型。</p><p>函数的列表如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">find_elements_by_id</span><br><span class="line">find_elements_by_name</span><br><span class="line">find_elements_by_xpath</span><br><span class="line">find_elements_by_link_text</span><br><span class="line">find_elements_by_partial_link_text</span><br><span class="line">find_elements_by_tag_name</span><br><span class="line">find_elements_by_class_name</span><br><span class="line">find_elements_by_css_selector</span><br></pre></td></tr></table></figure></p><p>当然我们和刚才一样，也可可以直接find_elements()方法来选择，所以也可以这样来写：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lis = browser.find_elements(By.CSS_SELECTOR, &apos;.service-bd li&apos;)</span><br></pre></td></tr></table></figure></p><p>结果是完全一致的。</p><h2 id="元素交互"><a href="#元素交互" class="headerlink" title="元素交互"></a>元素交互</h2><p>Selenium可以驱动浏览器来执行一些操作，也就是说我们可以让浏览器模拟执行一些动作，比较常见的用法有：</p><p>输入文字用send_keys()方法，清空文字用clear()方法，另外还有按钮点击，用click()方法。</p><p>我们用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.taobao.com&apos;)</span><br><span class="line">input = browser.find_element_by_id(&apos;q&apos;)</span><br><span class="line">input.send_keys(&apos;iPhone&apos;)</span><br><span class="line">time.sleep(1)</span><br><span class="line">input.clear()</span><br><span class="line">input.send_keys(&apos;iPad&apos;)</span><br><span class="line">button = browser.find_element_by_class_name(&apos;btn-search&apos;)</span><br><span class="line">button.click()</span><br></pre></td></tr></table></figure></p><p>在这里我们首先驱动浏览器打开淘宝，然后用find_element_by_id()方法获取输入框，然后用send_keys()方法输入iPhone文字，等待一秒之后用clear()方法清空输入框，再次调用send_keys()方法输入iPad文字，之后再用find_element_by_class_name()方法获取搜索按钮，最后调用click()方法完成搜索动作。</p><p>通过上面的方法我们就完成了一些常见元素的动作操作，更多的操作可以参见官方文档的交互动作介绍：<a href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.remote.webelement</a></p><h1 id="动作链"><a href="#动作链" class="headerlink" title="动作链"></a>动作链</h1><p>在上面的实例中，一些交互动作都是针对某个元素执行的，比如输入框我们就调用它的输入文字和清空文字方法，按钮就调用它的点击方法，其实还有另外的一些操作它是没有特定的执行对象的。比如鼠标拖拽，键盘按键等操作。所以这些动作我们有另一种方式来执行，那就是加到动作链中。</p><p>比如我们现在实现一个元素拖拽操作，将某个元素从一处拖拽到另外一处，我们用代码来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ActionChains</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = &apos;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&apos;</span><br><span class="line">browser.get(url)</span><br><span class="line">browser.switch_to.frame(&apos;iframeResult&apos;)</span><br><span class="line">source = browser.find_element_by_css_selector(&apos;#draggable&apos;)</span><br><span class="line">target = browser.find_element_by_css_selector(&apos;#droppable&apos;)</span><br><span class="line">actions = ActionChains(browser)</span><br><span class="line">actions.drag_and_drop(source, target)</span><br><span class="line">actions.perform()</span><br></pre></td></tr></table></figure></p><p>首先我们打开网页中的一个拖拽实例，然后依次选中要被拖拽的元素和拖拽到的目标元素，然后声明了ActionChains对象赋值为actions变量，然后通过调用actions变量的drag_and_drop()方法，然后再调用perform()方法执行动作，就完成了拖拽操作。</p><p>更多的动作链操作可以参考官方文档的动作链介绍：<a href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains</a></p><h1 id="执行JavaScript"><a href="#执行JavaScript" class="headerlink" title="执行JavaScript"></a>执行JavaScript</h1><p>另外对于某些操作，API没有提供的，如下拉进度条等，可以直接模拟运行JavaScript，使用execute_script()方法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.zhihu.com/explore&apos;)</span><br><span class="line">browser.execute_script(&apos;window.scrollTo(0, document.body.scrollHeight)&apos;)</span><br><span class="line">browser.execute_script(&apos;alert(&quot;To Bottom&quot;)&apos;)</span><br></pre></td></tr></table></figure></p><p>在这里我们就利用了execute_script()方法将进度条下拉到最底部，然后弹出alert提示框。</p><p>所以说有了这个，基本上API没有提供的所有的功能都可以用执行JavaScript的方式来实现了。</p><h1 id="获取元素信息"><a href="#获取元素信息" class="headerlink" title="获取元素信息"></a>获取元素信息</h1><p>我们在前面说过通过page_source属性可以获取网页的源代码，获取源代码之后就可以使用解析库如正则、BeautifulSoup、PyQuery等来提取信息了。</p><p>不过既然Selenium已经提供了选择元素的方法，返回的是WebElement类型，那么它也有相关的方法和属性来直接提取元素信息，如属性、文本等等。这样的话我们能就不用通过解析源代码来提取信息了，非常方便。</p><p>那接下来我们就看一下可以通过怎样的方式来获取元素信息吧。</p><h2 id="获取属性"><a href="#获取属性" class="headerlink" title="获取属性"></a>获取属性</h2><p>我们可以使用get_attribute()方法来获取元素的属性，那么这个的前提就是先选中这个元素。</p><p>我们用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver import ActionChains</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = &apos;https://www.zhihu.com/explore&apos;</span><br><span class="line">browser.get(url)</span><br><span class="line">logo = browser.find_element_by_id(&apos;zh-top-link-logo&apos;)</span><br><span class="line">print(logo)</span><br><span class="line">print(logo.get_attribute(&apos;class&apos;))</span><br></pre></td></tr></table></figure></p><p>运行之后程序便会驱动浏览器打开知乎的页面，然后获取知乎的LOGO元素，然后将它的class打印出来。</p><p>控制台输出结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;e08c0f28d7f44d75ccd50df6bb676104&quot;, element=&quot;0.7236390660048155-1&quot;)&gt;</span><br><span class="line">zu-top-link-logo</span><br></pre></td></tr></table></figure></p><p>我们通过get_attribute()方法，然后传入想要获取的属性名，就可以得到它的值了。</p><h2 id="获取文本值"><a href="#获取文本值" class="headerlink" title="获取文本值"></a>获取文本值</h2><p>每个WebEelement元素都有text属性，我们可以通过直接调用这个属性就可以得到元素内部的文本信息了，就相当于BeautifulSoup的get_text()方法、PyQuery的text()方法。</p><p>我们用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = &apos;https://www.zhihu.com/explore&apos;</span><br><span class="line">browser.get(url)</span><br><span class="line">input = browser.find_element_by_class_name(&apos;zu-top-add-question&apos;)</span><br><span class="line">print(input.text)</span><br></pre></td></tr></table></figure></p><p>在这里们依然是先打开知乎页面，然后获取提问按钮这个元素，再将其文本值打印出来。</p><p>控制台输出结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">提问</span><br><span class="line">获取ID、位置、标签名、大小</span><br></pre></td></tr></table></figure></p><p>另外WebElement元素还有一些其他的属性，比如id属性可以获取元素id，location可以获取该元素在页面中的相对位置，tag_name可以获取标签名称 ，size可以获取元素的大小，也就是宽高，这些属性有时候还是很有用的。</p><p>我们用实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = &apos;https://www.zhihu.com/explore&apos;</span><br><span class="line">browser.get(url)</span><br><span class="line">input = browser.find_element_by_class_name(&apos;zu-top-add-question&apos;)</span><br><span class="line">print(input.id)</span><br><span class="line">print(input.location)</span><br><span class="line">print(input.tag_name)</span><br><span class="line">print(input.size)</span><br><span class="line">在这里我们首先获得了提问按钮这个元素，然后调用其id、location、tag_name、size属性即可获取对应的属性值。</span><br></pre></td></tr></table></figure></p><h2 id="切换Frame"><a href="#切换Frame" class="headerlink" title="切换Frame"></a>切换Frame</h2><p>我们知道在网页中有这样一种标签叫做iframe，也就是子Frame，相当于页面的子页面，它的结构和外部网页的结构是完全一致的。Selenium打开页面后，它默认是在父级Frame里面操作，而此时如果页面中还有子Frame，它是不能获取到子Frame里面的元素的。所以这时候我们就需要使用switch_to.frame()方法来切换Frame。</p><p>我们首先用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.common.exceptions import NoSuchElementException</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">url = &apos;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&apos;</span><br><span class="line">browser.get(url)</span><br><span class="line">browser.switch_to.frame(&apos;iframeResult&apos;)</span><br><span class="line">try:</span><br><span class="line">    logo = browser.find_element_by_class_name(&apos;logo&apos;)</span><br><span class="line">except NoSuchElementException:</span><br><span class="line">    print(&apos;NO LOGO&apos;)</span><br><span class="line">browser.switch_to.parent_frame()</span><br><span class="line">logo = browser.find_element_by_class_name(&apos;logo&apos;)</span><br><span class="line">print(logo)</span><br><span class="line">print(logo.text)</span><br></pre></td></tr></table></figure></p><p>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NO LOGO</span><br><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;4bb8ac03ced4ecbdefef03ffdc0e4ccd&quot;, element=&quot;0.13792611320464965-2&quot;)&gt;</span><br><span class="line">RUNOOB.COM</span><br></pre></td></tr></table></figure></p><p>我们还是以上文演示动作链操作的网页为实例，首先我们通过switch_to.frame()方法切换到子Frame里面，然后我们尝试获取父级Frame里的LOGO元素，是不能找到的，找不到的话就会抛出NoSuchElementException异常，异常被捕捉之后就会输出NO LOGO，接下来我们重新切换回父Frame，然后再次重新获取元素，发现就可以成功获取了。</p><p>所以，当页面中包含子Frame时，如果我们想获取子Frame中的元素，需要先调用switch_to.frame()方法切换到对应的Frame，然后再进行操作。</p><h2 id="延时等待"><a href="#延时等待" class="headerlink" title="延时等待"></a>延时等待</h2><p>在Selenium中，get()方法会在网页框架加载结束之后就结束执行，此时如果获取page_source可能并不是浏览器完全加载完成的页面，如果某些页面有额外的Ajax请求，我们在网页源代码中也不一定能成功获取到。所以这里我们需要延时等待一定时间确保元素已经加载出来。</p><p>在这里等待的方式有两种，一种隐式等待，一种显式等待。</p><h3 id="隐式等待"><a href="#隐式等待" class="headerlink" title="隐式等待"></a>隐式等待</h3><p>当使用了隐式等待执行测试的时候，如果Selenium没有在DOM中找到元素，将继续等待，超出设定时间后则抛出找不到元素的异常, 换句话说，当查找元素而元素并没有立即出现的时候，隐式等待将等待一段时间再查找 DOM，默认的时间是0。</p><p>我们用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.implicitly_wait(10)</span><br><span class="line">browser.get(&apos;https://www.zhihu.com/explore&apos;)</span><br><span class="line">input = browser.find_element_by_class_name(&apos;zu-top-add-question&apos;)</span><br><span class="line">print(input)</span><br></pre></td></tr></table></figure></p><p>在这里我们用implicitly_wait()方法实现了隐式等待。</p><h3 id="显式等待"><a href="#显式等待" class="headerlink" title="显式等待"></a>显式等待</h3><p>隐式等待的效果其实并没有那么好，因为我们只是规定了一个固定时间，而页面的加载时间是受到网络条件影响的。</p><p>所以在这里还有一种更合适的显式等待方法，它指定好要查找的元素，然后指定一个最长等待时间。如果在规定时间内加载出来了这个元素，那就返回查找的元素，如果到了规定时间依然没有加载出该元素，则会抛出超时异常。</p><p>我们用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line">from selenium.webdriver.support.ui import WebDriverWait</span><br><span class="line">from selenium.webdriver.support import expected_conditions as EC</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.taobao.com/&apos;)</span><br><span class="line">wait = WebDriverWait(browser, 10)</span><br><span class="line">input = wait.until(EC.presence_of_element_located((By.ID, &apos;q&apos;)))</span><br><span class="line">button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, &apos;.btn-search&apos;)))</span><br><span class="line">print(input, button)</span><br></pre></td></tr></table></figure></p><p>在这里我们首先引入了WebDriverWait这个对象，指定好最长等待时间，然后调用它的until()方法，传入要等待条件expected_conditions，比如在这里我们传入了presence_of_element_located这个条件，就代表元素出现的意思，其参数是元素的定位元组，也就是ID为q的元素搜索框。</p><p>所以这样可以做到的效果就是，在10秒内如果ID为q的元素即搜索框成功加载出来了，那就返回该元素，如果超过10秒还没有加载出来，那就抛出异常。</p><p>对于按钮，可以更改一下等待条件，比如改为element_to_be_clickable，也就是可点击，所以查找按钮时是查找CSS选择器为.btn-search的按钮，如果10秒内它是可点击的也就是成功加载出来了，那就返回这个按钮元素，如果超过10秒还不可点击，也就是没有加载出来，那就抛出异常。</p><p>运行代码，在网速较佳的情况下是可以成功加载出来的。</p><p>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;07dd2fbc2d5b1ce40e82b9754aba8fa8&quot;, element=&quot;0.5642646294074107-1&quot;)&gt;</span><br><span class="line">&lt;selenium.webdriver.remote.webelement.WebElement (session=&quot;07dd2fbc2d5b1ce40e82b9754aba8fa8&quot;, element=&quot;0.5642646294074107-2&quot;)&gt;</span><br></pre></td></tr></table></figure></p><p>可以看到控制台成功输出了两个元素，都是WebElement类型。</p><p>如果网络有问题，10秒内没有成功加载，那就抛出TimeoutException，控制台输出如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TimeoutException Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-4-f3d73973b223&gt; in &lt;module&gt;()</span><br><span class="line">      7 browser.get(&apos;https://www.taobao.com/&apos;)</span><br><span class="line">      8 wait = WebDriverWait(browser, 10)</span><br><span class="line">----&gt; 9 input = wait.until(EC.presence_of_element_located((By.ID, &apos;q&apos;)))</span><br></pre></td></tr></table></figure></p><p>关于等待条件，其实还有很多，比如判断标题内容，判断某个元素内是否出现了某文字，在这里将所有的加载条件列举如下：</p><p>等待条件含义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">title_is标题是某内容</span><br><span class="line">title_contains标题包含某内容</span><br><span class="line">presence_of_element_located元素加载出，传入定位元组，如(By.ID, &apos;p&apos;)</span><br><span class="line">visibility_of_element_located元素可见，传入定位元组</span><br><span class="line">visibility_of可见，传入元素对象</span><br><span class="line">presence_of_all_elements_located所有元素加载出</span><br><span class="line">text_to_be_present_in_element某个元素文本包含某文字</span><br><span class="line">text_to_be_present_in_element_value某个元素值包含某文字</span><br><span class="line">frame_to_be_available_and_switch_to_it frame加载并切换</span><br><span class="line">invisibility_of_element_located元素不可见</span><br><span class="line">element_to_be_clickable元素可点击</span><br><span class="line">staleness_of判断一个元素是否仍在DOM，可判断页面是否已经刷新</span><br><span class="line">element_to_be_selected元素可选择，传元素对象</span><br><span class="line">element_located_to_be_selected元素可选择，传入定位元组</span><br><span class="line">element_selection_state_to_be传入元素对象以及状态，相等返回True，否则返回False</span><br><span class="line">element_located_selection_state_to_be传入定位元组以及状态，相等返回True，否则返回False</span><br><span class="line">alert_is_present是否出现Alert</span><br></pre></td></tr></table></figure></p><p>更多详细的等待条件的参数及用法介绍可以参考官方文档：<a href="http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions</a></p><h1 id="前进后退"><a href="#前进后退" class="headerlink" title="前进后退"></a>前进后退</h1><p>我们平常使用浏览器都有前进和后退功能，使用Selenium也可以完成这个操作，使用back()方法可以后退，forward()方法可以前进。</p><p>我们用一个实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.baidu.com/&apos;)</span><br><span class="line">browser.get(&apos;https://www.taobao.com/&apos;)</span><br><span class="line">browser.get(&apos;https://www.python.org/&apos;)</span><br><span class="line">browser.back()</span><br><span class="line">time.sleep(1)</span><br><span class="line">browser.forward()</span><br><span class="line">browser.close()</span><br></pre></td></tr></table></figure></p><p>在这里我们连续访问三个页面，然后调用back()方法就可以回到第二个页面，接下来再调用forward()方法又可以前进到第三个页面。</p><h1 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h1><p>使用Selenium还可以方便地对Cookies进行操作，例如获取、添加、删除Cookies等等。</p><p>我们再用实例来感受一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.zhihu.com/explore&apos;)</span><br><span class="line">print(browser.get_cookies())</span><br><span class="line">browser.add_cookie(&#123;&apos;name&apos;: &apos;name&apos;, &apos;domain&apos;: &apos;www.zhihu.com&apos;, &apos;value&apos;: &apos;germey&apos;&#125;)</span><br><span class="line">print(browser.get_cookies())</span><br><span class="line">browser.delete_all_cookies()</span><br><span class="line">print(browser.get_cookies())</span><br></pre></td></tr></table></figure></p><p>首先我们访问了知乎，然后加载完成之后，浏览器实际上已经生成了Cookies了，我们调用get_cookies()方法就可以获取所有的Cookies，然后我们添加一个Cookie，传入一个字典，有name、domain、value键名。接下来我们再次获取所有的Cookies，可以发现结果就多了这一项Cookie。最后我们调用delete_all_cookies()方法，删除所有的Cookies，再重新获取，结果就为空了。</p><p>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#123;&apos;secure&apos;: False, &apos;value&apos;: &apos;&quot;NGM0ZTM5NDAwMWEyNDQwNDk5ODlkZWY3OTkxY2I0NDY=|1491604091|236e34290a6f407bfbb517888849ea509ac366d0&quot;&apos;, &apos;domain&apos;: &apos;.zhihu.com&apos;, &apos;path&apos;: &apos;/&apos;, &apos;httpOnly&apos;: False, &apos;name&apos;: &apos;l_cap_id&apos;, &apos;expiry&apos;: 1494196091.403418&#125;]</span><br><span class="line">[&#123;&apos;secure&apos;: False, &apos;value&apos;: &apos;germey&apos;, &apos;domain&apos;: &apos;.www.zhihu.com&apos;, &apos;path&apos;: &apos;/&apos;, &apos;httpOnly&apos;: False, &apos;name&apos;: &apos;name&apos;&#125;, &#123;&apos;secure&apos;: False, &apos;value&apos;: &apos;&quot;NGM0ZTM5NDAwMWEyNDQwNDk5ODlkZWY3OTkxY2I0NDY=|1491604091|236e34290a6f407bfbb517888849ea509ac366d0&quot;&apos;, &apos;domain&apos;: &apos;.zhihu.com&apos;, &apos;path&apos;: &apos;/&apos;, &apos;httpOnly&apos;: False, &apos;name&apos;: &apos;l_cap_id&apos;, &apos;expiry&apos;: 1494196091.403418&#125;]</span><br><span class="line">[]</span><br></pre></td></tr></table></figure></p><p>因此通过以上方法来操作Cookies还是非常方便的。</p><h1 id="选项卡管理"><a href="#选项卡管理" class="headerlink" title="选项卡管理"></a>选项卡管理</h1><p>我们在访问网页的时候会开启一个个选项卡，那么在Selenium中也可以对选项卡进行操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.baidu.com&apos;)</span><br><span class="line">browser.execute_script(&apos;window.open()&apos;)</span><br><span class="line">print(browser.window_handles)</span><br><span class="line">browser.switch_to_window(browser.window_handles[1])</span><br><span class="line">browser.get(&apos;https://www.taobao.com&apos;)</span><br><span class="line">time.sleep(1)</span><br><span class="line">browser.switch_to_window(browser.window_handles[0])</span><br><span class="line">browser.get(&apos;https://python.org&apos;)</span><br></pre></td></tr></table></figure></p><p>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&apos;CDwindow-4f58e3a7-7167-4587-bedf-9cd8c867f435&apos;, &apos;CDwindow-6e05f076-6d77-453a-a36c-32baacc447df&apos;]</span><br></pre></td></tr></table></figure></p><p>首先我们访问了百度，然后调用了execute_script()方法，传入window.open()方法新开启一个选项卡，然后接下来我们想切换到该选项卡，可以调用window_handles属性获取当前开启的所有选项卡，返回的是选项卡的代号列表，要想切换选项卡只需要调用switch_to_window()方法，传入选项卡的代号即可。在这里我们将第二个选项卡代号传入，即跳转到了第二个选项卡，然后接下来在第二个选项卡下打开一个新的页面，然后切换回第一个选项卡可以重新调用switch_to_window()方法，再执行其他操作即可。</p><p>如此以来我们便实现了选项卡的管理。</p><h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h1><p>在使用Selenium过程中，难免会遇到一些异常，例如超时、元素未找到等错误，一旦出现此类错误，程序便不会继续运行了，所以异常处理在程序中是十分重要的。</p><p>在这里我们可以使用try..except来捕获各种异常。</p><p>首先我们演示一下元素未找到的异常，示例如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get(&apos;https://www.baidu.com&apos;)</span><br><span class="line">browser.find_element_by_id(&apos;hello&apos;)</span><br></pre></td></tr></table></figure></p><p>在这里我们打开百度页面，然后尝试选择一个并不存在的元素，这样就会遇到异常。</p><p>运行之后控制台输出如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NoSuchElementException Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input-23-978945848a1b&gt; in &lt;module&gt;()</span><br><span class="line">      3 browser = webdriver.Chrome()</span><br><span class="line">      4 browser.get(&apos;https://www.baidu.com&apos;)</span><br><span class="line">----&gt; 5 browser.find_element_by_id(&apos;hello&apos;)</span><br></pre></td></tr></table></figure></p><p>可以看到抛出了NoSuchElementException这类异常，这通常是元素未找到的异常，为了防止程序遇到异常而中断，我们需要捕获一下这些异常。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">from selenium import webdriver</span><br><span class="line">from selenium.common.exceptions import TimeoutException, NoSuchElementException</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">try:</span><br><span class="line">    browser.get(&apos;https://www.baidu.com&apos;)</span><br><span class="line">except TimeoutException:</span><br><span class="line">    print(&apos;Time Out&apos;)</span><br><span class="line">try:</span><br><span class="line">    browser.find_element_by_id(&apos;hello&apos;)</span><br><span class="line">except NoSuchElementException:</span><br><span class="line">    print(&apos;No Element&apos;)</span><br><span class="line">finally:</span><br><span class="line">    browser.close()</span><br></pre></td></tr></table></figure></p><p>如上例锁上，这里我们使用try..except来捕获各类异常，比如我们对find_element_by_id查找元素的方法捕获NoSuchElementException，这样一旦出现这样的错误，就进行异常处理，程序也不会中断了。</p><p>控制台输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">No Element</span><br></pre></td></tr></table></figure></p><p>更多的异常累可以参考官方文档：<a href="http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions，如果出现了某个异常，我们对它进行捕获即可。" target="_blank" rel="noopener">http://selenium-python.readthedocs.io/api.html#module-selenium.common.exceptions，如果出现了某个异常，我们对它进行捕获即可。</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;selenium可以解决js渲染问题，模拟网页加载。&lt;/p&gt;
&lt;h1 id=&quot;简单示例&quot;&gt;&lt;a href=&quot;#简单示例&quot; class=&quot;headerlink&quot; title=&quot;简单示例&quot;&gt;&lt;/a&gt;简单示例&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;from selenium import webdriver&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;from selenium.webdriver.common.by import By&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;from selenium.webdriver.common.keys import Keys&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;from selenium.webdriver.support import expected_conditions as EC&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;from selenium.webdriver.support.wait import WebDriverWait&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;browser = webdriver.Chrome()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;try:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    browser.get(&amp;apos;https://www.baidu.com&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input = browser.find_element_by_id(&amp;apos;kw&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input.send_keys(&amp;apos;Python&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    input.send_keys(Keys.ENTER)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    wait = WebDriverWait(browser, 10)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    wait.until(EC.presence_of_element_located((By.ID, &amp;apos;content_left&amp;apos;)))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(browser.current_url)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(browser.get_cookies())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    print(browser.page_source)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;finally:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    browser.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行代码之后，如果正确配置好了ChromeDriver，可以发现会自动弹出一个浏览器，浏览器首先会跳转到百度，然后在搜索框中输入Python进行搜索，然后跳转到搜索结果页，等待搜索结果加载出来之后，控制台分别会输出当前的URL，当前的Cookies还有网页源代码。&lt;br&gt;
    
    </summary>
    
      <category term="爬虫" scheme="https://snjl.github.io/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="爬虫" scheme="https://snjl.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="selenium" scheme="https://snjl.github.io/tags/selenium/"/>
    
  </entry>
  
  <entry>
    <title>requests库的get和post方法</title>
    <link href="https://snjl.github.io/2019/01/31/requests%E5%BA%93%E7%9A%84get%E5%92%8Cpost%E6%96%B9%E6%B3%95/"/>
    <id>https://snjl.github.io/2019/01/31/requests库的get和post方法/</id>
    <published>2019-01-31T06:26:13.000Z</published>
    <updated>2019-01-31T06:28:42.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="获取网页的方式"><a href="#获取网页的方式" class="headerlink" title="获取网页的方式"></a>获取网页的方式</h1><p>其实在加载网页的时候, 有几种类型, 而这几种类型就是你打开网页的关键. 最重要的类型 (method) 就是 get 和 post (当然还有其他的, 比如 head, delete)。</p><p>以下分析两个重要的类型的重要特点。</p><h2 id="post"><a href="#post" class="headerlink" title="post"></a>post</h2><ul><li>账号登录</li><li>搜索内容</li><li>上传图片</li><li>上传文件</li><li>往服务器传数据等<h2 id="get"><a href="#get" class="headerlink" title="get"></a>get</h2></li><li>正常打开网页</li><li>不往服务器传数据<br>这样看来, 很多网页使用 get 就可以了, 而 post, 我们则是给服务器发送个性化请求, 比如将你的账号密码传给服务器, 让它给你返回一个含有你个人信息的 HTML.</li></ul><p>从主动和被动的角度来说, post 中文是发送, 比较主动, 你控制了服务器返回的内容. 而 get 中文是取得, 是被动的, 你没有发送给服务器个性化的信息, 它不会根据你个性化的信息返回不一样的 HTML.</p><h1 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h1><p>get请求的参数一般是在网址后面加入?parameter1=xxx&amp;parameter2=xxxx，使用?传递参数，用&amp;并列参数。</p><p>使用requests的包直接请求baidu，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.get(&quot;http://www.baidu.com&quot;)</span><br><span class="line">&gt;&gt;&gt; r.text</span><br><span class="line">&apos;&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;ç\x99¾åº¦ä¸\x80ä</span><br><span class="line">···</span><br></pre></td></tr></table></figure><p>r.text得到的是unicode编码数据，可能会出现乱码，可以使用r.encoding = ‘utf8’强制转换后再提取<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r.encoding=&apos;utf8&apos;</span><br><span class="line">&gt;&gt;&gt; r.text</span><br><span class="line">&apos;&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt;</span><br><span class="line">···</span><br></pre></td></tr></table></figure></p><p><strong>注意：注意：response.content得到的是二进制数据，而response.text得到的是Unicode编码数据，一般content用于获取图片、视频等，text用于获取文字类数据。</strong></p><p>访问<a href="http://httpbin/get" target="_blank" rel="noopener">http://httpbin/get</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.get(&apos;http://httpbin.org/get&apos;)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;,</span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*/*&quot;,</span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,</span><br><span class="line">    &quot;Connection&quot;: &quot;close&quot;,</span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests/2.18.4&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;origin&quot;: &quot;xxx.xxx.xxx.xxx&quot;,</span><br><span class="line">  &quot;url&quot;: &quot;http://httpbin.org/get&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果带参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.get(&apos;http://httpbin.org/get?a=2&amp;c=3&amp;w=&apos;)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;</span><br><span class="line">    &quot;a&quot;: &quot;2&quot;,</span><br><span class="line">    &quot;c&quot;: &quot;3&quot;,</span><br><span class="line">    &quot;w&quot;: &quot;&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">···</span><br></pre></td></tr></table></figure></p><p>可以看到他获取到了参数并且输出了。</p><p>也可以使用另一种写法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.get(&apos;http://httpbin.org/get&apos;,params=parameter)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;</span><br><span class="line">    &quot;a&quot;: &quot;23&quot;,</span><br><span class="line">    &quot;b&quot;: &quot;32&quot;,</span><br><span class="line">    &quot;c&quot;: &quot;string&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*/*&quot;,</span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,</span><br><span class="line">    &quot;Connection&quot;: &quot;close&quot;,</span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests/2.18.4&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;origin&quot;: &quot;xxx.xxx.xxx.xxx&quot;,</span><br><span class="line">  &quot;url&quot;: &quot;http://httpbin.org/get?a=23&amp;b=32&amp;c=string&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以直接使用json方法转化成json（与使用json的loads效果一样）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r.json</span><br><span class="line">&lt;bound method Response.json of &lt;Response [200]&gt;&gt;</span><br><span class="line">&gt;&gt;&gt; r.json()</span><br><span class="line">&#123;&apos;args&apos;: &#123;&apos;a&apos;: &apos;23&apos;, &apos;b&apos;: &apos;32&apos;, &apos;c&apos;: &apos;string&apos;&#125;, &apos;headers&apos;: &#123;&apos;Accept&apos;: &apos;*/*&apos;, &apos;Accept-Encoding&apos;: &apos;gzip, deflate&apos;, &apos;Connection&apos;: &apos;close&apos;, &apos;Host&apos;: &apos;httpbin.org&apos;, &apos;User-Agent&apos;: &apos;python-requests/2.18.4&apos;&#125;, &apos;origin&apos;: &apos;115.153.174.11&apos;, &apos;url&apos;: &apos;http://httpbin.org/get?a=23&amp;b=32&amp;c=string&apos;&#125;</span><br></pre></td></tr></table></figure></p><p>有一些网页不使用headers无法访问，例如知乎，使用headers：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; headers = &#123;&apos;User-agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.26 Safari/537.36 Core/1.63.5221.400 QQBrowser/10.0.1125.400&apos;&#125;</span><br><span class="line">&gt;&gt;&gt; r = requests.get(&quot;http://www.zhihu.com&quot;)</span><br><span class="line">&gt;&gt;&gt; print(r)</span><br><span class="line">&lt;Response [400]&gt;</span><br><span class="line">&gt;&gt;&gt; r = requests.get(&quot;http://www.zhihu.com&quot;,headers=headers)</span><br><span class="line">&gt;&gt;&gt; r</span><br><span class="line">&lt;Response [200]&gt;</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p><p>可以通过r.headers看到请求头信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r.headers</span><br><span class="line">&#123;&apos;Date&apos;: &apos;Tue, 29 Jan 2019 09:05:50 GMT&apos;, &apos;Content-Type&apos;: &apos;text/html; charset=utf-8&apos;, &apos;Transfer-Encoding&apos;: &apos;chunked&apos;, &apos;Connection&apos;: &apos;keep-alive&apos;, &apos;Vary&apos;: &apos;Accept-Encoding&apos;, &apos;Content-Security-Policy&apos;: &quot;default-src * blob:; img-src * data: blob:; connect-src * wss: blob:; frame-src &apos;self&apos; *.zhihu.com weixin: *.vzuu.com getpocket.com note.youdao.com safari-extension://com.evernote.safari.clipper-Q79WDW8YH9 zhihujs: captcha.guard.qcloud.com; script-src &apos;self&apos; blob: *.zhihu.com res.wx.qq.com &apos;unsafe-eval&apos; unpkg.zhimg.com unicom.zhimg.com captcha.gtimg.com captcha.guard.qcloud.com pagead2.googlesyndication.com i.hao61.net &apos;nonce-a0691bfd-cf49-40b4-8ad7-37d552f59c50&apos;; style-src &apos;self&apos; &apos;unsafe-inline&apos; *.zhihu.com unicom.zhimg.com captcha.gtimg.com&quot;, &apos;X-Frame-Options&apos;: &apos;SAMEORIGIN&apos;, &apos;Strict-Transport-Security&apos;: &apos;max-age=15552000; includeSubDomains&apos;, &apos;Surrogate-Control&apos;: &apos;no-store&apos;, &apos;Cache-Control&apos;: &apos;no-store, no-cache, must-revalidate, proxy-revalidate&apos;, &apos;Pragma&apos;: &apos;no-cache&apos;, &apos;Expires&apos;: &apos;0&apos;, &apos;X-Content-Type-Options&apos;: &apos;nosniff&apos;, &apos;X-XSS-Protection&apos;: &apos;1; mode=block&apos;, &apos;Content-Encoding&apos;: &apos;gzip&apos;, &apos;Server&apos;: &apos;ZWS&apos;&#125;</span><br></pre></td></tr></table></figure></p><h1 id="post方法"><a href="#post方法" class="headerlink" title="post方法"></a>post方法</h1><p>最简单的依然是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.post(&quot;http://httpbin.org/post&quot;)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;,</span><br><span class="line">  &quot;data&quot;: &quot;&quot;,</span><br><span class="line">  &quot;files&quot;: &#123;&#125;,</span><br><span class="line">  &quot;form&quot;: &#123;&#125;,</span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*/*&quot;,</span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,</span><br><span class="line">    &quot;Connection&quot;: &quot;close&quot;,</span><br><span class="line">    &quot;Content-Length&quot;: &quot;0&quot;,</span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests/2.18.4&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;json&quot;: null,</span><br><span class="line">  &quot;origin&quot;: &quot;xxx.xxx.xxx.xxx&quot;,</span><br><span class="line">  &quot;url&quot;: &quot;http://httpbin.org/post&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>传入参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.post(&quot;http://httpbin.org/post&quot;,params=parameter)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;</span><br><span class="line">    &quot;a&quot;: &quot;23&quot;,</span><br><span class="line">    &quot;b&quot;: &quot;32&quot;,</span><br><span class="line">    &quot;c&quot;: &quot;string&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">···</span><br></pre></td></tr></table></figure></p><p>使用headers和get方法一样。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;获取网页的方式&quot;&gt;&lt;a href=&quot;#获取网页的方式&quot; class=&quot;headerlink&quot; title=&quot;获取网页的方式&quot;&gt;&lt;/a&gt;获取网页的方式&lt;/h1&gt;&lt;p&gt;其实在加载网页的时候, 有几种类型, 而这几种类型就是你打开网页的关键. 最重要的类型 (metho
      
    
    </summary>
    
      <category term="python" scheme="https://snjl.github.io/categories/python/"/>
    
    
      <category term="python" scheme="https://snjl.github.io/tags/python/"/>
    
      <category term="爬虫" scheme="https://snjl.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
</feed>
